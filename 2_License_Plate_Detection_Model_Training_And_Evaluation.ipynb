{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detection - Data Collection and Exploration\n",
    "Welcome to the license plate detection! This notebook explains step-by-step how to train and use a license plate detection model for the Machine Learning Engineer Capstone Project. Make sure you meet all preconditions before you start, see README.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import matplotlib\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Tensorflow version..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 1.13.1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print (\"Tensorflow: {}\".format(tf.__version__))\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.13.1'):\n",
    "    raise ImportError('Please upgrade your TensorFlow installation to v1.13.1')\n",
    "\n",
    "if StrictVersion(tf.__version__) >= StrictVersion('2.0.0'):\n",
    "    raise ImportError('Please downgrade your TensorFlow installation to v1.13.*.')\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print(f\"GPU device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images inside the notebook cells.\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'tf_object_detection'))\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(working_dir)\n",
    "sys.path.append(working_dir + \"/slim\")\n",
    "\n",
    "path = working_dir + ';' + working_dir + '/slim' + ';' + working_dir + '/object_detection'\n",
    "os.environ['PYTHONPATH'] = path\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'object_detection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation\n",
    "\n",
    "#### Variables\n",
    "Define the pretrained model to be used.\n",
    "Change MODEL and PIPELINE_CONFING_FILENAME if you want to use other pretrained models, see the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pretrained model\n",
    "MODEL = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "PIPELINE_CONFING_FILENAME = 'ssdlite_mobilenet_v2_coco.config'\n",
    "\n",
    "#MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "#PIPELINE_CONFING_FILENAME = 'ssd_mobilenet_v2.config'\n",
    "\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels file:           ../../config/plate_detection\\labels_map.pbtxt\n",
      "Pipeline config file:  ../../config/plate_detection\\ssdlite_mobilenet_v2_coco.config\n",
      "Checkpoints directory: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\n",
      "Frozen model file:     ../../output/plate_detection/fine_tuned_models/ssdlite_mobilenet_v2_coco_2018_05_09\\frozen_inference_graph.pb\n",
      "TFLite model file:     ../../output/plate_detection\\glpd-model-float.tflite\n"
     ]
    }
   ],
   "source": [
    "# ****************** don't edit ******************\n",
    "\n",
    "# What model to download.\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "PRETRAIND_MODELS_DIR = 'models'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "DETECTION_COFIG_DIR = '../../config/plate_detection'\n",
    "PATH_TO_LABELS = os.path.join(DETECTION_COFIG_DIR, 'labels_map.pbtxt')\n",
    "\n",
    "PIPELINE_CONFING_FILEPATH = os.path.join(DETECTION_COFIG_DIR, PIPELINE_CONFING_FILENAME)\n",
    "\n",
    "OUTPUT_DIR = '../../output/plate_detection'\n",
    "CHECKPOINTS_DIR = OUTPUT_DIR + '/checkpoints/' + MODEL\n",
    "FINETUNED_MODEL_DIR = OUTPUT_DIR + '/fine_tuned_models/' + MODEL\n",
    "\n",
    "# Path to frozen detection graph.\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(FINETUNED_MODEL_DIR, 'frozen_inference_graph.pb')\n",
    "\n",
    "TFLITE_MODEL_PATH = os.path.join(OUTPUT_DIR, 'glpd-model-float.tflite')\n",
    "\n",
    "print ('Labels file:           {}'.format(PATH_TO_LABELS))\n",
    "print ('Pipeline config file:  {}'.format(PIPELINE_CONFING_FILEPATH))\n",
    "print ('Checkpoints directory: {}'.format(CHECKPOINTS_DIR))\n",
    "print ('Frozen model file:     {}'.format(PATH_TO_FROZEN_GRAPH))\n",
    "print ('TFLite model file:     {}'.format(TFLITE_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Traffic Light Detection Model\n",
    "\n",
    "**NOTE:** If you have already trained the model, you can skip the training- and export steps and proceed directly with testing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Pretrained Model\n",
    "\n",
    "**NOTE:** This step only needs to be done once if the pretrained model has not been downloaded yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ZIP = os.path.join(PRETRAIND_MODELS_DIR, MODEL_FILE)\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_ZIP)\n",
    "tar_file = tarfile.open(MODEL_ZIP)\n",
    "tar_file.extractall(os.path.join(os.getcwd(), PRETRAIND_MODELS_DIR))\n",
    "tar_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Finetuned Model\n",
    "\n",
    "Starts the training. This step may take several hours, depending on the computing power of your computer.\n",
    "You can monitor the training process using tensorboard tensorboard --logdir=%CHECKPOINTS_DIR% and stop the training if once the desired accuracy has been achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E0290984E0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001E02908EE18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\builders\\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\utils\\ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\inputs.py:287: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\core\\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\core\\preprocessor.py:1218: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\builders\\dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:loss = 11.053393, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.45366\n",
      "INFO:tensorflow:loss = 4.7770586, step = 100 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56673\n",
      "INFO:tensorflow:loss = 2.7802205, step = 200 (63.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57968\n",
      "INFO:tensorflow:loss = 2.9189224, step = 300 (63.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58408\n",
      "INFO:tensorflow:loss = 3.1690025, step = 400 (63.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59038\n",
      "INFO:tensorflow:loss = 2.2350316, step = 500 (62.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59258\n",
      "INFO:tensorflow:loss = 1.9185493, step = 600 (62.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58667\n",
      "INFO:tensorflow:loss = 2.248416, step = 700 (63.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59\n",
      "INFO:tensorflow:loss = 2.7644389, step = 800 (62.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58715\n",
      "INFO:tensorflow:loss = 1.4865445, step = 900 (63.044 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 929 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\utils\\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:09:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-929\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.581\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:09:39\n",
      "INFO:tensorflow:Saving dict for global step 929: DetectionBoxes_Precision/mAP = 0.21955995, DetectionBoxes_Precision/mAP (large) = 0.24938384, DetectionBoxes_Precision/mAP (medium) = 0.27906442, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.58072233, DetectionBoxes_Precision/mAP@.75IOU = 0.06766815, DetectionBoxes_Recall/AR@1 = 0.24761905, DetectionBoxes_Recall/AR@10 = 0.26190478, DetectionBoxes_Recall/AR@100 = 0.26190478, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = 0.29473683, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 4.7069907, Loss/localization_loss = 2.5767212, Loss/regularization_loss = 0.26792714, Loss/total_loss = 7.5516386, global_step = 929, learning_rate = 0.004, loss = 7.5516386\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 929: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-929\n",
      "INFO:tensorflow:global_step/sec: 0.980704\n",
      "INFO:tensorflow:loss = 2.3349867, step = 1000 (101.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58486\n",
      "INFO:tensorflow:loss = 1.5575612, step = 1100 (63.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55267\n",
      "INFO:tensorflow:loss = 1.8884404, step = 1200 (64.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55145\n",
      "INFO:tensorflow:loss = 1.76633, step = 1300 (64.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54181\n",
      "INFO:tensorflow:loss = 1.4611709, step = 1400 (64.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56986\n",
      "INFO:tensorflow:loss = 1.3394883, step = 1500 (63.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55698\n",
      "INFO:tensorflow:loss = 2.5255833, step = 1600 (64.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56814\n",
      "INFO:tensorflow:loss = 1.1828951, step = 1700 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55894\n",
      "INFO:tensorflow:loss = 1.4629807, step = 1800 (64.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1806 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:19:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-1806\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.589\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:19:41\n",
      "INFO:tensorflow:Saving dict for global step 1806: DetectionBoxes_Precision/mAP = 0.21670584, DetectionBoxes_Precision/mAP (large) = 0.2506739, DetectionBoxes_Precision/mAP (medium) = 0.272684, DetectionBoxes_Precision/mAP (small) = 0.004950495, DetectionBoxes_Precision/mAP@.50IOU = 0.58866036, DetectionBoxes_Precision/mAP@.75IOU = 0.03570357, DetectionBoxes_Recall/AR@1 = 0.23571429, DetectionBoxes_Recall/AR@10 = 0.26904762, DetectionBoxes_Recall/AR@100 = 0.26904762, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = 0.31578946, DetectionBoxes_Recall/AR@100 (small) = 0.014285714, Loss/classification_loss = 4.9176683, Loss/localization_loss = 2.4751089, Loss/regularization_loss = 0.26894596, Loss/total_loss = 7.6617227, global_step = 1806, learning_rate = 0.004, loss = 7.6617227\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1806: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-1806\n",
      "INFO:tensorflow:global_step/sec: 1.02071\n",
      "INFO:tensorflow:loss = 1.4980515, step = 1900 (98.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56492\n",
      "INFO:tensorflow:loss = 1.6271307, step = 2000 (63.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5751\n",
      "INFO:tensorflow:loss = 1.0337682, step = 2100 (63.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57272\n",
      "INFO:tensorflow:loss = 2.350081, step = 2200 (63.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55831\n",
      "INFO:tensorflow:loss = 1.8033535, step = 2300 (64.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56998\n",
      "INFO:tensorflow:loss = 1.5622387, step = 2400 (63.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57876\n",
      "INFO:tensorflow:loss = 2.3688521, step = 2500 (63.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54909\n",
      "INFO:tensorflow:loss = 1.2500135, step = 2600 (64.510 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2692 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.2364\n",
      "INFO:tensorflow:loss = 1.1001835, step = 2700 (80.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57896\n",
      "INFO:tensorflow:loss = 1.209598, step = 2800 (63.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57003\n",
      "INFO:tensorflow:loss = 1.8806893, step = 2900 (63.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57265\n",
      "INFO:tensorflow:loss = 1.4885614, step = 3000 (63.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57075\n",
      "INFO:tensorflow:loss = 1.107662, step = 3100 (63.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 1.7617247, step = 3200 (63.572 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.56433\n",
      "INFO:tensorflow:loss = 1.1049042, step = 3300 (63.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57292\n",
      "INFO:tensorflow:loss = 1.3004199, step = 3400 (63.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55393\n",
      "INFO:tensorflow:loss = 1.5349876, step = 3500 (64.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54842\n",
      "INFO:tensorflow:loss = 1.0030417, step = 3600 (64.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3607 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:39:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-3607\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:39:42\n",
      "INFO:tensorflow:Saving dict for global step 3607: DetectionBoxes_Precision/mAP = 0.25504938, DetectionBoxes_Precision/mAP (large) = 0.27252045, DetectionBoxes_Precision/mAP (medium) = 0.31691545, DetectionBoxes_Precision/mAP (small) = 0.18811882, DetectionBoxes_Precision/mAP@.50IOU = 0.62265885, DetectionBoxes_Precision/mAP@.75IOU = 0.069464415, DetectionBoxes_Recall/AR@1 = 0.2809524, DetectionBoxes_Recall/AR@10 = 0.32142857, DetectionBoxes_Recall/AR@100 = 0.32142857, DetectionBoxes_Recall/AR@100 (large) = 0.35625, DetectionBoxes_Recall/AR@100 (medium) = 0.34210527, DetectionBoxes_Recall/AR@100 (small) = 0.18571429, Loss/classification_loss = 4.609881, Loss/localization_loss = 2.3032577, Loss/regularization_loss = 0.2703162, Loss/total_loss = 7.183454, global_step = 3607, learning_rate = 0.004, loss = 7.183454\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3607: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-3607\n",
      "INFO:tensorflow:global_step/sec: 1.00377\n",
      "INFO:tensorflow:loss = 1.5041399, step = 3700 (99.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54668\n",
      "INFO:tensorflow:loss = 1.3290677, step = 3800 (64.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57364\n",
      "INFO:tensorflow:loss = 1.0991906, step = 3900 (63.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57201\n",
      "INFO:tensorflow:loss = 1.9540477, step = 4000 (63.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55468\n",
      "INFO:tensorflow:loss = 1.1397275, step = 4100 (64.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5724\n",
      "INFO:tensorflow:loss = 1.2353792, step = 4200 (63.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57525\n",
      "INFO:tensorflow:loss = 1.9099083, step = 4300 (63.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58015\n",
      "INFO:tensorflow:loss = 1.2401619, step = 4400 (63.238 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4493 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:49:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-4493\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:49:41\n",
      "INFO:tensorflow:Saving dict for global step 4493: DetectionBoxes_Precision/mAP = 0.25252178, DetectionBoxes_Precision/mAP (large) = 0.2842914, DetectionBoxes_Precision/mAP (medium) = 0.30819568, DetectionBoxes_Precision/mAP (small) = 0.12143564, DetectionBoxes_Precision/mAP@.50IOU = 0.59457046, DetectionBoxes_Precision/mAP@.75IOU = 0.0893063, DetectionBoxes_Recall/AR@1 = 0.27857143, DetectionBoxes_Recall/AR@10 = 0.33095238, DetectionBoxes_Recall/AR@100 = 0.33095238, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = 0.34736842, DetectionBoxes_Recall/AR@100 (small) = 0.21428572, Loss/classification_loss = 4.8375907, Loss/localization_loss = 2.1584802, Loss/regularization_loss = 0.27083874, Loss/total_loss = 7.266911, global_step = 4493, learning_rate = 0.004, loss = 7.266911\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4493: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-4493\n",
      "INFO:tensorflow:global_step/sec: 1.03365\n",
      "INFO:tensorflow:loss = 1.1504732, step = 4500 (96.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58113\n",
      "INFO:tensorflow:loss = 1.596603, step = 4600 (63.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1421664, step = 4700 (63.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55024\n",
      "INFO:tensorflow:loss = 1.7200829, step = 4800 (64.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57508\n",
      "INFO:tensorflow:loss = 1.3275857, step = 4900 (63.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56178\n",
      "INFO:tensorflow:loss = 1.25367, step = 5000 (63.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56199\n",
      "INFO:tensorflow:loss = 1.2727109, step = 5100 (64.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56502\n",
      "INFO:tensorflow:loss = 1.1996188, step = 5200 (63.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56688\n",
      "INFO:tensorflow:loss = 0.9918119, step = 5300 (63.863 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5381 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:59:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-5381\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:59:42\n",
      "INFO:tensorflow:Saving dict for global step 5381: DetectionBoxes_Precision/mAP = 0.27836335, DetectionBoxes_Precision/mAP (large) = 0.31867683, DetectionBoxes_Precision/mAP (medium) = 0.3134803, DetectionBoxes_Precision/mAP (small) = 0.22227722, DetectionBoxes_Precision/mAP@.50IOU = 0.71754545, DetectionBoxes_Precision/mAP@.75IOU = 0.09156141, DetectionBoxes_Recall/AR@1 = 0.30714285, DetectionBoxes_Recall/AR@10 = 0.37142858, DetectionBoxes_Recall/AR@100 = 0.37142858, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.36842105, DetectionBoxes_Recall/AR@100 (small) = 0.3, Loss/classification_loss = 4.0200434, Loss/localization_loss = 2.047714, Loss/regularization_loss = 0.27120948, Loss/total_loss = 6.338967, global_step = 5381, learning_rate = 0.004, loss = 6.338967\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5381: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-5381\n",
      "INFO:tensorflow:global_step/sec: 1.02757\n",
      "INFO:tensorflow:loss = 1.0050988, step = 5400 (97.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55826\n",
      "INFO:tensorflow:loss = 0.92588156, step = 5500 (64.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57493\n",
      "INFO:tensorflow:loss = 1.3314233, step = 5600 (63.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56924\n",
      "INFO:tensorflow:loss = 0.94624555, step = 5700 (63.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56548\n",
      "INFO:tensorflow:loss = 1.1352828, step = 5800 (63.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56902\n",
      "INFO:tensorflow:loss = 0.9881964, step = 5900 (63.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5713\n",
      "INFO:tensorflow:loss = 1.1309838, step = 6000 (63.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55458\n",
      "INFO:tensorflow:loss = 1.2333928, step = 6100 (64.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56779\n",
      "INFO:tensorflow:loss = 1.1549134, step = 6200 (63.737 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6269 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:09:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-6269\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:09:42\n",
      "INFO:tensorflow:Saving dict for global step 6269: DetectionBoxes_Precision/mAP = 0.2884612, DetectionBoxes_Precision/mAP (large) = 0.29693156, DetectionBoxes_Precision/mAP (medium) = 0.34050855, DetectionBoxes_Precision/mAP (small) = 0.28638613, DetectionBoxes_Precision/mAP@.50IOU = 0.71921694, DetectionBoxes_Precision/mAP@.75IOU = 0.09614697, DetectionBoxes_Recall/AR@1 = 0.33333334, DetectionBoxes_Recall/AR@10 = 0.38809523, DetectionBoxes_Recall/AR@100 = 0.38809523, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.38947368, DetectionBoxes_Recall/AR@100 (small) = 0.34285715, Loss/classification_loss = 3.9325256, Loss/localization_loss = 1.9067831, Loss/regularization_loss = 0.27157977, Loss/total_loss = 6.110888, global_step = 6269, learning_rate = 0.004, loss = 6.110888\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6269: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-6269\n",
      "INFO:tensorflow:global_step/sec: 1.03151\n",
      "INFO:tensorflow:loss = 1.1578708, step = 6300 (96.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57089\n",
      "INFO:tensorflow:loss = 0.94521916, step = 6400 (63.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0671122, step = 6500 (63.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55647\n",
      "INFO:tensorflow:loss = 1.0933914, step = 6600 (64.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56294\n",
      "INFO:tensorflow:loss = 1.0086803, step = 6700 (64.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58098\n",
      "INFO:tensorflow:loss = 0.91134095, step = 6800 (63.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59223\n",
      "INFO:tensorflow:loss = 1.0346198, step = 6900 (62.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58065\n",
      "INFO:tensorflow:loss = 0.82258916, step = 7000 (63.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58502\n",
      "INFO:tensorflow:loss = 1.151697, step = 7100 (63.147 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7162 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:19:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-7162\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:19:42\n",
      "INFO:tensorflow:Saving dict for global step 7162: DetectionBoxes_Precision/mAP = 0.2887178, DetectionBoxes_Precision/mAP (large) = 0.29356945, DetectionBoxes_Precision/mAP (medium) = 0.35687637, DetectionBoxes_Precision/mAP (small) = 0.21856436, DetectionBoxes_Precision/mAP@.50IOU = 0.6976918, DetectionBoxes_Precision/mAP@.75IOU = 0.14432031, DetectionBoxes_Recall/AR@1 = 0.35, DetectionBoxes_Recall/AR@10 = 0.37380952, DetectionBoxes_Recall/AR@100 = 0.37380952, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.38421053, DetectionBoxes_Recall/AR@100 (small) = 0.27142859, Loss/classification_loss = 4.5566554, Loss/localization_loss = 1.8952757, Loss/regularization_loss = 0.2718522, Loss/total_loss = 6.7237825, global_step = 7162, learning_rate = 0.004, loss = 6.7237825\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7162: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-7162\n",
      "INFO:tensorflow:global_step/sec: 1.03614\n",
      "INFO:tensorflow:loss = 1.2179914, step = 7200 (96.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59213\n",
      "INFO:tensorflow:loss = 0.87403876, step = 7300 (62.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58745\n",
      "INFO:tensorflow:loss = 1.2556773, step = 7400 (62.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58624\n",
      "INFO:tensorflow:loss = 0.9953369, step = 7500 (63.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58977\n",
      "INFO:tensorflow:loss = 0.9945806, step = 7600 (62.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58864\n",
      "INFO:tensorflow:loss = 1.0065402, step = 7700 (62.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58406\n",
      "INFO:tensorflow:loss = 0.9290036, step = 7800 (63.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59312\n",
      "INFO:tensorflow:loss = 1.2035403, step = 7900 (62.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58524\n",
      "INFO:tensorflow:loss = 0.960917, step = 8000 (63.038 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8063 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:29:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8063\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.777\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:29:43\n",
      "INFO:tensorflow:Saving dict for global step 8063: DetectionBoxes_Precision/mAP = 0.33763, DetectionBoxes_Precision/mAP (large) = 0.38174534, DetectionBoxes_Precision/mAP (medium) = 0.37249666, DetectionBoxes_Precision/mAP (small) = 0.30792078, DetectionBoxes_Precision/mAP@.50IOU = 0.7773255, DetectionBoxes_Precision/mAP@.75IOU = 0.20206332, DetectionBoxes_Recall/AR@1 = 0.3809524, DetectionBoxes_Recall/AR@10 = 0.43333334, DetectionBoxes_Recall/AR@100 = 0.43333334, DetectionBoxes_Recall/AR@100 (large) = 0.45625, DetectionBoxes_Recall/AR@100 (medium) = 0.4368421, DetectionBoxes_Recall/AR@100 (small) = 0.37142858, Loss/classification_loss = 4.0042467, Loss/localization_loss = 1.6922796, Loss/regularization_loss = 0.27210844, Loss/total_loss = 5.968635, global_step = 8063, learning_rate = 0.004, loss = 5.968635\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8063: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8063\n",
      "INFO:tensorflow:global_step/sec: 1.03541\n",
      "INFO:tensorflow:loss = 1.1531446, step = 8100 (96.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58589\n",
      "INFO:tensorflow:loss = 0.8470978, step = 8200 (63.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.91215503, step = 8300 (63.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59297\n",
      "INFO:tensorflow:loss = 1.0126481, step = 8400 (62.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59\n",
      "INFO:tensorflow:loss = 0.9959841, step = 8500 (62.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58597\n",
      "INFO:tensorflow:loss = 0.9886245, step = 8600 (63.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59114\n",
      "INFO:tensorflow:loss = 0.80002624, step = 8700 (62.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5894\n",
      "INFO:tensorflow:loss = 0.93394667, step = 8800 (62.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58418\n",
      "INFO:tensorflow:loss = 1.6092228, step = 8900 (63.168 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8963 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:39:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8963\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:39:43\n",
      "INFO:tensorflow:Saving dict for global step 8963: DetectionBoxes_Precision/mAP = 0.33193263, DetectionBoxes_Precision/mAP (large) = 0.3808868, DetectionBoxes_Precision/mAP (medium) = 0.35935172, DetectionBoxes_Precision/mAP (small) = 0.3049505, DetectionBoxes_Precision/mAP@.50IOU = 0.7654584, DetectionBoxes_Precision/mAP@.75IOU = 0.1754643, DetectionBoxes_Recall/AR@1 = 0.3857143, DetectionBoxes_Recall/AR@10 = 0.44761905, DetectionBoxes_Recall/AR@100 = 0.44761905, DetectionBoxes_Recall/AR@100 (large) = 0.4875, DetectionBoxes_Recall/AR@100 (medium) = 0.4368421, DetectionBoxes_Recall/AR@100 (small) = 0.3857143, Loss/classification_loss = 3.8525648, Loss/localization_loss = 1.5553297, Loss/regularization_loss = 0.27231607, Loss/total_loss = 5.68021, global_step = 8963, learning_rate = 0.004, loss = 5.68021\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8963: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8963\n",
      "INFO:tensorflow:global_step/sec: 1.04066\n",
      "INFO:tensorflow:loss = 0.9091662, step = 9000 (96.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5863\n",
      "INFO:tensorflow:loss = 0.9809174, step = 9100 (63.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59048\n",
      "INFO:tensorflow:loss = 0.9433055, step = 9200 (62.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58677\n",
      "INFO:tensorflow:loss = 1.4902347, step = 9300 (63.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59213\n",
      "INFO:tensorflow:loss = 1.1695669, step = 9400 (62.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58457\n",
      "INFO:tensorflow:loss = 1.4232985, step = 9500 (63.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5874\n",
      "INFO:tensorflow:loss = 1.0455487, step = 9600 (62.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58793\n",
      "INFO:tensorflow:loss = 1.2096956, step = 9700 (63.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58268\n",
      "INFO:tensorflow:loss = 1.6367497, step = 9800 (63.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9863 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:49:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-9863\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:49:43\n",
      "INFO:tensorflow:Saving dict for global step 9863: DetectionBoxes_Precision/mAP = 0.3601881, DetectionBoxes_Precision/mAP (large) = 0.41168198, DetectionBoxes_Precision/mAP (medium) = 0.38401112, DetectionBoxes_Precision/mAP (small) = 0.36353135, DetectionBoxes_Precision/mAP@.50IOU = 0.7738264, DetectionBoxes_Precision/mAP@.75IOU = 0.24431352, DetectionBoxes_Recall/AR@1 = 0.45238096, DetectionBoxes_Recall/AR@10 = 0.4952381, DetectionBoxes_Recall/AR@100 = 0.4952381, DetectionBoxes_Recall/AR@100 (large) = 0.51875, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = 0.42857143, Loss/classification_loss = 4.119317, Loss/localization_loss = 1.3893025, Loss/regularization_loss = 0.2725325, Loss/total_loss = 5.781152, global_step = 9863, learning_rate = 0.004, loss = 5.781152\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9863: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-9863\n",
      "INFO:tensorflow:global_step/sec: 1.03923\n",
      "INFO:tensorflow:loss = 1.7237545, step = 9900 (96.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58932\n",
      "INFO:tensorflow:loss = 1.4906914, step = 10000 (62.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.77266514, step = 10100 (63.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58695\n",
      "INFO:tensorflow:loss = 0.976238, step = 10200 (62.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58947\n",
      "INFO:tensorflow:loss = 0.7733383, step = 10300 (62.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58584\n",
      "INFO:tensorflow:loss = 1.1590183, step = 10400 (63.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58448\n",
      "INFO:tensorflow:loss = 1.1206701, step = 10500 (63.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58333\n",
      "INFO:tensorflow:loss = 0.85948205, step = 10600 (63.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58043\n",
      "INFO:tensorflow:loss = 0.71612775, step = 10700 (63.317 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10762 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:59:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-10762\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.829\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:59:45\n",
      "INFO:tensorflow:Saving dict for global step 10762: DetectionBoxes_Precision/mAP = 0.3922996, DetectionBoxes_Precision/mAP (large) = 0.45440143, DetectionBoxes_Precision/mAP (medium) = 0.4020533, DetectionBoxes_Precision/mAP (small) = 0.40965346, DetectionBoxes_Precision/mAP@.50IOU = 0.829103, DetectionBoxes_Precision/mAP@.75IOU = 0.24389522, DetectionBoxes_Recall/AR@1 = 0.4738095, DetectionBoxes_Recall/AR@10 = 0.4904762, DetectionBoxes_Recall/AR@100 = 0.4904762, DetectionBoxes_Recall/AR@100 (large) = 0.525, DetectionBoxes_Recall/AR@100 (medium) = 0.47894737, DetectionBoxes_Recall/AR@100 (small) = 0.44285715, Loss/classification_loss = 3.1704524, Loss/localization_loss = 1.274271, Loss/regularization_loss = 0.2727635, Loss/total_loss = 4.7174873, global_step = 10762, learning_rate = 0.004, loss = 4.7174873\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10762: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-10762\n",
      "INFO:tensorflow:global_step/sec: 1.02207\n",
      "INFO:tensorflow:loss = 1.2882607, step = 10800 (97.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58085\n",
      "INFO:tensorflow:loss = 1.1375971, step = 10900 (63.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48489\n",
      "INFO:tensorflow:loss = 1.6180861, step = 11000 (67.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56561\n",
      "INFO:tensorflow:loss = 0.8557518, step = 11100 (63.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57831\n",
      "INFO:tensorflow:loss = 1.2817976, step = 11200 (63.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5688\n",
      "INFO:tensorflow:loss = 0.96116847, step = 11300 (63.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57938\n",
      "INFO:tensorflow:loss = 1.2490941, step = 11400 (63.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5495\n",
      "INFO:tensorflow:loss = 1.0169579, step = 11500 (64.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55783\n",
      "INFO:tensorflow:loss = 0.85584235, step = 11600 (64.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11644 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.22468\n",
      "INFO:tensorflow:loss = 1.1488913, step = 11700 (81.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47528\n",
      "INFO:tensorflow:loss = 0.9103625, step = 11800 (67.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48467\n",
      "INFO:tensorflow:loss = 0.93949485, step = 11900 (67.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55626\n",
      "INFO:tensorflow:loss = 0.92879784, step = 12000 (64.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53853\n",
      "INFO:tensorflow:loss = 0.93614954, step = 12100 (65.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53117\n",
      "INFO:tensorflow:loss = 0.6210952, step = 12200 (65.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55251\n",
      "INFO:tensorflow:loss = 0.7947601, step = 12300 (64.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56321\n",
      "INFO:tensorflow:loss = 0.96878326, step = 12400 (63.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55886\n",
      "INFO:tensorflow:loss = 0.64113784, step = 12500 (64.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12539 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:19:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-12539\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:19:44\n",
      "INFO:tensorflow:Saving dict for global step 12539: DetectionBoxes_Precision/mAP = 0.49922308, DetectionBoxes_Precision/mAP (large) = 0.5653875, DetectionBoxes_Precision/mAP (medium) = 0.48202696, DetectionBoxes_Precision/mAP (small) = 0.530363, DetectionBoxes_Precision/mAP@.50IOU = 0.89282936, DetectionBoxes_Precision/mAP@.75IOU = 0.43679586, DetectionBoxes_Recall/AR@1 = 0.552381, DetectionBoxes_Recall/AR@10 = 0.58809525, DetectionBoxes_Recall/AR@100 = 0.58809525, DetectionBoxes_Recall/AR@100 (large) = 0.63125, DetectionBoxes_Recall/AR@100 (medium) = 0.55789477, DetectionBoxes_Recall/AR@100 (small) = 0.5714286, Loss/classification_loss = 3.1979833, Loss/localization_loss = 0.98951423, Loss/regularization_loss = 0.27301437, Loss/total_loss = 4.4605117, global_step = 12539, learning_rate = 0.004, loss = 4.4605117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12539: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-12539\n",
      "INFO:tensorflow:global_step/sec: 1.03821\n",
      "INFO:tensorflow:loss = 1.2462051, step = 12600 (96.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56725\n",
      "INFO:tensorflow:loss = 0.8063697, step = 12700 (63.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55241\n",
      "INFO:tensorflow:loss = 1.0532905, step = 12800 (64.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55166\n",
      "INFO:tensorflow:loss = 1.0592431, step = 12900 (64.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52611\n",
      "INFO:tensorflow:loss = 1.080258, step = 13000 (65.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55485\n",
      "INFO:tensorflow:loss = 0.78680813, step = 13100 (64.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49452\n",
      "INFO:tensorflow:loss = 1.3208898, step = 13200 (66.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52253\n",
      "INFO:tensorflow:loss = 1.1211048, step = 13300 (65.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51162\n",
      "INFO:tensorflow:loss = 1.2905009, step = 13400 (66.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13412 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:29:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-13412\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.919\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.576\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:29:46\n",
      "INFO:tensorflow:Saving dict for global step 13412: DetectionBoxes_Precision/mAP = 0.5168004, DetectionBoxes_Precision/mAP (large) = 0.61555976, DetectionBoxes_Precision/mAP (medium) = 0.48324242, DetectionBoxes_Precision/mAP (small) = 0.5061056, DetectionBoxes_Precision/mAP@.50IOU = 0.91946447, DetectionBoxes_Precision/mAP@.75IOU = 0.5446482, DetectionBoxes_Recall/AR@1 = 0.5761905, DetectionBoxes_Recall/AR@10 = 0.59761906, DetectionBoxes_Recall/AR@100 = 0.59761906, DetectionBoxes_Recall/AR@100 (large) = 0.65625, DetectionBoxes_Recall/AR@100 (medium) = 0.56842107, DetectionBoxes_Recall/AR@100 (small) = 0.54285717, Loss/classification_loss = 2.4788606, Loss/localization_loss = 0.88989294, Loss/regularization_loss = 0.27311417, Loss/total_loss = 3.6418679, global_step = 13412, learning_rate = 0.004, loss = 3.6418679\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13412: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-13412\n",
      "INFO:tensorflow:global_step/sec: 1.01785\n",
      "INFO:tensorflow:loss = 0.87178636, step = 13500 (98.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57356\n",
      "INFO:tensorflow:loss = 1.0850344, step = 13600 (63.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57084\n",
      "INFO:tensorflow:loss = 1.0126143, step = 13700 (63.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57314\n",
      "INFO:tensorflow:loss = 1.3520375, step = 13800 (63.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56811\n",
      "INFO:tensorflow:loss = 0.94509256, step = 13900 (63.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55378\n",
      "INFO:tensorflow:loss = 1.1087849, step = 14000 (64.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55265\n",
      "INFO:tensorflow:loss = 1.4385773, step = 14100 (64.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5571\n",
      "INFO:tensorflow:loss = 1.8357592, step = 14200 (64.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14298 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:39:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-14298\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.616\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:39:47\n",
      "INFO:tensorflow:Saving dict for global step 14298: DetectionBoxes_Precision/mAP = 0.5614403, DetectionBoxes_Precision/mAP (large) = 0.6475208, DetectionBoxes_Precision/mAP (medium) = 0.54146665, DetectionBoxes_Precision/mAP (small) = 0.50425744, DetectionBoxes_Precision/mAP@.50IOU = 0.9633074, DetectionBoxes_Precision/mAP@.75IOU = 0.6158065, DetectionBoxes_Recall/AR@1 = 0.6142857, DetectionBoxes_Recall/AR@10 = 0.64047617, DetectionBoxes_Recall/AR@100 = 0.64047617, DetectionBoxes_Recall/AR@100 (large) = 0.6875, DetectionBoxes_Recall/AR@100 (medium) = 0.63684213, DetectionBoxes_Recall/AR@100 (small) = 0.54285717, Loss/classification_loss = 1.8925078, Loss/localization_loss = 0.7839102, Loss/regularization_loss = 0.27316922, Loss/total_loss = 2.9495873, global_step = 14298, learning_rate = 0.004, loss = 2.9495873\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14298: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-14298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01978\n",
      "INFO:tensorflow:loss = 0.9002887, step = 14300 (98.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56991\n",
      "INFO:tensorflow:loss = 0.91000843, step = 14400 (63.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5707\n",
      "INFO:tensorflow:loss = 0.81264305, step = 14500 (63.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57124\n",
      "INFO:tensorflow:loss = 0.81513053, step = 14600 (63.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 0.8372662, step = 14700 (63.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56152\n",
      "INFO:tensorflow:loss = 0.87939274, step = 14800 (63.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56211\n",
      "INFO:tensorflow:loss = 0.76295626, step = 14900 (64.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55836\n",
      "INFO:tensorflow:loss = 1.021116, step = 15000 (64.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55446\n",
      "INFO:tensorflow:loss = 1.2083338, step = 15100 (64.375 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15184 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24706\n",
      "INFO:tensorflow:loss = 0.96930647, step = 15200 (80.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56814\n",
      "INFO:tensorflow:loss = 0.6780444, step = 15300 (63.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57709\n",
      "INFO:tensorflow:loss = 1.1074436, step = 15400 (63.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55693\n",
      "INFO:tensorflow:loss = 1.1565608, step = 15500 (64.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56887\n",
      "INFO:tensorflow:loss = 1.030092, step = 15600 (63.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56774\n",
      "INFO:tensorflow:loss = 0.68787956, step = 15700 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.991865\n",
      "INFO:tensorflow:loss = 1.0062313, step = 15800 (100.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15870 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:00:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-15870\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.738\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.643\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:00:21\n",
      "INFO:tensorflow:Saving dict for global step 15870: DetectionBoxes_Precision/mAP = 0.6064884, DetectionBoxes_Precision/mAP (large) = 0.69591576, DetectionBoxes_Precision/mAP (medium) = 0.5733023, DetectionBoxes_Precision/mAP (small) = 0.59240925, DetectionBoxes_Precision/mAP@.50IOU = 0.9579542, DetectionBoxes_Precision/mAP@.75IOU = 0.7384766, DetectionBoxes_Recall/AR@1 = 0.64761907, DetectionBoxes_Recall/AR@10 = 0.68095237, DetectionBoxes_Recall/AR@100 = 0.68095237, DetectionBoxes_Recall/AR@100 (large) = 0.73125, DetectionBoxes_Recall/AR@100 (medium) = 0.6526316, DetectionBoxes_Recall/AR@100 (small) = 0.64285713, Loss/classification_loss = 1.7238725, Loss/localization_loss = 0.5887839, Loss/regularization_loss = 0.27324325, Loss/total_loss = 2.5858994, global_step = 15870, learning_rate = 0.004, loss = 2.5858994\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15870: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-15870\n",
      "INFO:tensorflow:global_step/sec: 0.314359\n",
      "INFO:tensorflow:loss = 0.883607, step = 15900 (318.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.317727\n",
      "INFO:tensorflow:loss = 0.6040118, step = 16000 (314.800 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16064 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:10:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16064\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.975\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:10:22\n",
      "INFO:tensorflow:Saving dict for global step 16064: DetectionBoxes_Precision/mAP = 0.6219332, DetectionBoxes_Precision/mAP (large) = 0.70883775, DetectionBoxes_Precision/mAP (medium) = 0.5945535, DetectionBoxes_Precision/mAP (small) = 0.53943896, DetectionBoxes_Precision/mAP@.50IOU = 0.97462386, DetectionBoxes_Precision/mAP@.75IOU = 0.7289741, DetectionBoxes_Recall/AR@1 = 0.68095237, DetectionBoxes_Recall/AR@10 = 0.6857143, DetectionBoxes_Recall/AR@100 = 0.6857143, DetectionBoxes_Recall/AR@100 (large) = 0.75, DetectionBoxes_Recall/AR@100 (medium) = 0.6631579, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 1.5667795, Loss/localization_loss = 0.5852163, Loss/regularization_loss = 0.27324012, Loss/total_loss = 2.4252362, global_step = 16064, learning_rate = 0.004, loss = 2.4252362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16064: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16064\n",
      "INFO:tensorflow:global_step/sec: 0.344691\n",
      "INFO:tensorflow:loss = 1.2935743, step = 16100 (290.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.378348\n",
      "INFO:tensorflow:loss = 0.8552778, step = 16200 (264.355 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16272 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:20:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16272\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:20:35\n",
      "INFO:tensorflow:Saving dict for global step 16272: DetectionBoxes_Precision/mAP = 0.6255399, DetectionBoxes_Precision/mAP (large) = 0.6928599, DetectionBoxes_Precision/mAP (medium) = 0.5952943, DetectionBoxes_Precision/mAP (small) = 0.6089109, DetectionBoxes_Precision/mAP@.50IOU = 0.97706807, DetectionBoxes_Precision/mAP@.75IOU = 0.78562766, DetectionBoxes_Recall/AR@1 = 0.6857143, DetectionBoxes_Recall/AR@10 = 0.6880952, DetectionBoxes_Recall/AR@100 = 0.6880952, DetectionBoxes_Recall/AR@100 (large) = 0.725, DetectionBoxes_Recall/AR@100 (medium) = 0.66842103, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.5801471, Loss/localization_loss = 0.5756079, Loss/regularization_loss = 0.27324077, Loss/total_loss = 2.4289956, global_step = 16272, learning_rate = 0.004, loss = 2.4289956\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16272: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16272\n",
      "INFO:tensorflow:global_step/sec: 0.295482\n",
      "INFO:tensorflow:loss = 0.8404789, step = 16300 (338.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.376848\n",
      "INFO:tensorflow:loss = 0.8106563, step = 16400 (265.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16480 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.36582\n",
      "INFO:tensorflow:loss = 0.6431481, step = 16500 (273.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.399239\n",
      "INFO:tensorflow:loss = 0.7752738, step = 16600 (250.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666021\n",
      "INFO:tensorflow:loss = 0.93368864, step = 16700 (150.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57085\n",
      "INFO:tensorflow:loss = 1.1761229, step = 16800 (63.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16892 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:40:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16892\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.792\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.613\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:40:25\n",
      "INFO:tensorflow:Saving dict for global step 16892: DetectionBoxes_Precision/mAP = 0.642096, DetectionBoxes_Precision/mAP (large) = 0.7137838, DetectionBoxes_Precision/mAP (medium) = 0.60927624, DetectionBoxes_Precision/mAP (small) = 0.6128713, DetectionBoxes_Precision/mAP@.50IOU = 0.9863113, DetectionBoxes_Precision/mAP@.75IOU = 0.79225093, DetectionBoxes_Recall/AR@1 = 0.6952381, DetectionBoxes_Recall/AR@10 = 0.6952381, DetectionBoxes_Recall/AR@100 = 0.6952381, DetectionBoxes_Recall/AR@100 (large) = 0.74375, DetectionBoxes_Recall/AR@100 (medium) = 0.66842103, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.5993516, Loss/localization_loss = 0.5835063, Loss/regularization_loss = 0.27324685, Loss/total_loss = 2.456105, global_step = 16892, learning_rate = 0.004, loss = 2.456105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16892: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16892\n",
      "INFO:tensorflow:global_step/sec: 0.975222\n",
      "INFO:tensorflow:loss = 0.9713135, step = 16900 (102.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56067\n",
      "INFO:tensorflow:loss = 0.6992128, step = 17000 (64.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56552\n",
      "INFO:tensorflow:loss = 1.1359767, step = 17100 (63.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57706\n",
      "INFO:tensorflow:loss = 0.9338313, step = 17200 (63.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55381\n",
      "INFO:tensorflow:loss = 0.9387554, step = 17300 (64.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57065\n",
      "INFO:tensorflow:loss = 0.8930064, step = 17400 (63.631 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.57592\n",
      "INFO:tensorflow:loss = 0.9464767, step = 17500 (63.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54444\n",
      "INFO:tensorflow:loss = 1.0903716, step = 17600 (64.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54579\n",
      "INFO:tensorflow:loss = 1.1474949, step = 17700 (64.726 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17769 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24533\n",
      "INFO:tensorflow:loss = 0.78269476, step = 17800 (80.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55907\n",
      "INFO:tensorflow:loss = 0.91491616, step = 17900 (64.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5725\n",
      "INFO:tensorflow:loss = 0.88213885, step = 18000 (63.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55741\n",
      "INFO:tensorflow:loss = 1.0519183, step = 18100 (64.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56375\n",
      "INFO:tensorflow:loss = 0.9124009, step = 18200 (63.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56806\n",
      "INFO:tensorflow:loss = 1.1280371, step = 18300 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51692\n",
      "INFO:tensorflow:loss = 0.9728357, step = 18400 (65.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55154\n",
      "INFO:tensorflow:loss = 0.80196345, step = 18500 (64.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56964\n",
      "INFO:tensorflow:loss = 0.7255701, step = 18600 (63.660 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18679 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:00:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-18679\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:00:21\n",
      "INFO:tensorflow:Saving dict for global step 18679: DetectionBoxes_Precision/mAP = 0.6869603, DetectionBoxes_Precision/mAP (large) = 0.7441254, DetectionBoxes_Precision/mAP (medium) = 0.66416097, DetectionBoxes_Precision/mAP (small) = 0.64908063, DetectionBoxes_Precision/mAP@.50IOU = 0.9969997, DetectionBoxes_Precision/mAP@.75IOU = 0.9078267, DetectionBoxes_Recall/AR@1 = 0.73333335, DetectionBoxes_Recall/AR@10 = 0.73333335, DetectionBoxes_Recall/AR@100 = 0.73333335, DetectionBoxes_Recall/AR@100 (large) = 0.76875, DetectionBoxes_Recall/AR@100 (medium) = 0.7157895, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 1.4347214, Loss/localization_loss = 0.39434963, Loss/regularization_loss = 0.27321532, Loss/total_loss = 2.102286, global_step = 18679, learning_rate = 0.004, loss = 2.102286\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18679: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-18679\n",
      "INFO:tensorflow:global_step/sec: 1.02138\n",
      "INFO:tensorflow:loss = 0.6798589, step = 18700 (97.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56757\n",
      "INFO:tensorflow:loss = 1.0436704, step = 18800 (63.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56289\n",
      "INFO:tensorflow:loss = 0.7282069, step = 18900 (64.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 1.0322585, step = 19000 (63.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58464\n",
      "INFO:tensorflow:loss = 1.00373, step = 19100 (63.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57426\n",
      "INFO:tensorflow:loss = 0.844666, step = 19200 (63.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.543\n",
      "INFO:tensorflow:loss = 0.87813723, step = 19300 (64.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53936\n",
      "INFO:tensorflow:loss = 1.1613348, step = 19400 (64.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54708\n",
      "INFO:tensorflow:loss = 0.8205923, step = 19500 (64.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19563 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24824\n",
      "INFO:tensorflow:loss = 0.7625221, step = 19600 (80.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5686\n",
      "INFO:tensorflow:loss = 0.7731677, step = 19700 (63.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56267\n",
      "INFO:tensorflow:loss = 0.8618427, step = 19800 (63.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56544\n",
      "INFO:tensorflow:loss = 0.8546407, step = 19900 (63.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56828\n",
      "INFO:tensorflow:loss = 1.3111031, step = 20000 (63.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56309\n",
      "INFO:tensorflow:loss = 0.8288491, step = 20100 (64.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5616\n",
      "INFO:tensorflow:loss = 0.87856007, step = 20200 (63.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55111\n",
      "INFO:tensorflow:loss = 0.8171362, step = 20300 (64.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56045\n",
      "INFO:tensorflow:loss = 0.79535747, step = 20400 (64.043 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20476 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:20:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-20476\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.699\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.882\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.619\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:20:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 20476: DetectionBoxes_Precision/mAP = 0.69901836, DetectionBoxes_Precision/mAP (large) = 0.7628584, DetectionBoxes_Precision/mAP (medium) = 0.67839986, DetectionBoxes_Precision/mAP (small) = 0.61915135, DetectionBoxes_Precision/mAP@.50IOU = 0.9615337, DetectionBoxes_Precision/mAP@.75IOU = 0.8822593, DetectionBoxes_Recall/AR@1 = 0.7404762, DetectionBoxes_Recall/AR@10 = 0.7404762, DetectionBoxes_Recall/AR@100 = 0.7404762, DetectionBoxes_Recall/AR@100 (large) = 0.79375, DetectionBoxes_Recall/AR@100 (medium) = 0.7157895, DetectionBoxes_Recall/AR@100 (small) = 0.6857143, Loss/classification_loss = 1.3517916, Loss/localization_loss = 0.39165568, Loss/regularization_loss = 0.2731545, Loss/total_loss = 2.016602, global_step = 20476, learning_rate = 0.004, loss = 2.016602\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20476: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-20476\n",
      "INFO:tensorflow:global_step/sec: 1.02505\n",
      "INFO:tensorflow:loss = 0.799726, step = 20500 (97.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57447\n",
      "INFO:tensorflow:loss = 0.72079635, step = 20600 (63.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57369\n",
      "INFO:tensorflow:loss = 0.9073359, step = 20700 (63.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56187\n",
      "INFO:tensorflow:loss = 1.5515928, step = 20800 (63.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56796\n",
      "INFO:tensorflow:loss = 0.87144166, step = 20900 (63.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57764\n",
      "INFO:tensorflow:loss = 0.9749163, step = 21000 (63.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57238\n",
      "INFO:tensorflow:loss = 1.0355136, step = 21100 (63.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57565\n",
      "INFO:tensorflow:loss = 0.6866902, step = 21200 (63.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58391\n",
      "INFO:tensorflow:loss = 0.69730806, step = 21300 (63.175 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21368 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:30:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-21368\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.861\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.615\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.726\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:30:21\n",
      "INFO:tensorflow:Saving dict for global step 21368: DetectionBoxes_Precision/mAP = 0.7073704, DetectionBoxes_Precision/mAP (large) = 0.77702326, DetectionBoxes_Precision/mAP (medium) = 0.6940058, DetectionBoxes_Precision/mAP (small) = 0.6152145, DetectionBoxes_Precision/mAP@.50IOU = 0.959461, DetectionBoxes_Precision/mAP@.75IOU = 0.86071026, DetectionBoxes_Recall/AR@1 = 0.74761903, DetectionBoxes_Recall/AR@10 = 0.74761903, DetectionBoxes_Recall/AR@100 = 0.74761903, DetectionBoxes_Recall/AR@100 (large) = 0.80625, DetectionBoxes_Recall/AR@100 (medium) = 0.7263158, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.2012084, Loss/localization_loss = 0.36212203, Loss/regularization_loss = 0.2731154, Loss/total_loss = 1.8364462, global_step = 21368, learning_rate = 0.004, loss = 1.8364462\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21368: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-21368\n",
      "INFO:tensorflow:global_step/sec: 1.03669\n",
      "INFO:tensorflow:loss = 0.68299955, step = 21400 (96.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58788\n",
      "INFO:tensorflow:loss = 0.7283222, step = 21500 (63.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58431\n",
      "INFO:tensorflow:loss = 0.84869087, step = 21600 (63.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59119\n",
      "INFO:tensorflow:loss = 0.8874027, step = 21700 (62.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5901\n",
      "INFO:tensorflow:loss = 0.87586397, step = 21800 (62.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59157\n",
      "INFO:tensorflow:loss = 0.8719399, step = 21900 (62.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58791\n",
      "INFO:tensorflow:loss = 1.2967674, step = 22000 (62.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5898\n",
      "INFO:tensorflow:loss = 1.2427669, step = 22100 (62.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58265\n",
      "INFO:tensorflow:loss = 0.65139127, step = 22200 (63.143 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22269 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.26494\n",
      "INFO:tensorflow:loss = 0.73308, step = 22300 (79.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58738\n",
      "INFO:tensorflow:loss = 0.8266683, step = 22400 (62.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59038\n",
      "INFO:tensorflow:loss = 0.73603874, step = 22500 (62.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59051\n",
      "INFO:tensorflow:loss = 1.4147407, step = 22600 (62.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58993\n",
      "INFO:tensorflow:loss = 1.0635802, step = 22700 (62.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58466\n",
      "INFO:tensorflow:loss = 0.8350389, step = 22800 (63.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59253\n",
      "INFO:tensorflow:loss = 0.77145517, step = 22900 (62.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58579\n",
      "INFO:tensorflow:loss = 0.86105484, step = 23000 (63.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58931\n",
      "INFO:tensorflow:loss = 0.81072986, step = 23100 (62.949 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23197 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:50:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-23197\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.608\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.815\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.726\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:50:22\n",
      "INFO:tensorflow:Saving dict for global step 23197: DetectionBoxes_Precision/mAP = 0.72519535, DetectionBoxes_Precision/mAP (large) = 0.81514525, DetectionBoxes_Precision/mAP (medium) = 0.6975975, DetectionBoxes_Precision/mAP (small) = 0.6080622, DetectionBoxes_Precision/mAP@.50IOU = 0.9641468, DetectionBoxes_Precision/mAP@.75IOU = 0.8812984, DetectionBoxes_Recall/AR@1 = 0.7619048, DetectionBoxes_Recall/AR@10 = 0.7619048, DetectionBoxes_Recall/AR@100 = 0.7619048, DetectionBoxes_Recall/AR@100 (large) = 0.85, DetectionBoxes_Recall/AR@100 (medium) = 0.7263158, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.717074, Loss/localization_loss = 0.3734939, Loss/regularization_loss = 0.2729295, Loss/total_loss = 2.3634975, global_step = 23197, learning_rate = 0.004, loss = 2.3634975\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 23197: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-23197\n",
      "INFO:tensorflow:global_step/sec: 1.04114\n",
      "INFO:tensorflow:loss = 0.6659199, step = 23200 (96.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57878\n",
      "INFO:tensorflow:loss = 1.8969074, step = 23300 (63.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57188\n",
      "INFO:tensorflow:loss = 0.7378943, step = 23400 (63.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54285\n",
      "INFO:tensorflow:loss = 0.91421247, step = 23500 (64.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56755\n",
      "INFO:tensorflow:loss = 1.0277197, step = 23600 (63.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58496\n",
      "INFO:tensorflow:loss = 0.64031607, step = 23700 (63.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58682\n",
      "INFO:tensorflow:loss = 0.71459186, step = 23800 (62.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59023\n",
      "INFO:tensorflow:loss = 1.0704232, step = 23900 (62.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58088\n",
      "INFO:tensorflow:loss = 1.1263257, step = 24000 (63.210 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24091 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:00:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24091\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.648\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.753\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:00:22\n",
      "INFO:tensorflow:Saving dict for global step 24091: DetectionBoxes_Precision/mAP = 0.7231673, DetectionBoxes_Precision/mAP (large) = 0.758775, DetectionBoxes_Precision/mAP (medium) = 0.7174343, DetectionBoxes_Precision/mAP (small) = 0.64848655, DetectionBoxes_Precision/mAP@.50IOU = 0.95492333, DetectionBoxes_Precision/mAP@.75IOU = 0.9401619, DetectionBoxes_Recall/AR@1 = 0.75476193, DetectionBoxes_Recall/AR@10 = 0.75476193, DetectionBoxes_Recall/AR@100 = 0.75476193, DetectionBoxes_Recall/AR@100 (large) = 0.79375, DetectionBoxes_Recall/AR@100 (medium) = 0.7526316, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.5016155, Loss/localization_loss = 0.36365736, Loss/regularization_loss = 0.27286178, Loss/total_loss = 2.1381345, global_step = 24091, learning_rate = 0.004, loss = 2.1381345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24091: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24091\n",
      "INFO:tensorflow:global_step/sec: 1.03873\n",
      "INFO:tensorflow:loss = 0.9755063, step = 24100 (96.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59309\n",
      "INFO:tensorflow:loss = 0.7597003, step = 24200 (62.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59086\n",
      "INFO:tensorflow:loss = 0.61712456, step = 24300 (62.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58471\n",
      "INFO:tensorflow:loss = 0.7111548, step = 24400 (63.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58846\n",
      "INFO:tensorflow:loss = 0.7269006, step = 24500 (62.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58748\n",
      "INFO:tensorflow:loss = 1.5439472, step = 24600 (62.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59137\n",
      "INFO:tensorflow:loss = 0.78630674, step = 24700 (62.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56057\n",
      "INFO:tensorflow:loss = 0.8128227, step = 24800 (64.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57891\n",
      "INFO:tensorflow:loss = 1.27707, step = 24900 (63.364 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24989 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:10:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24989\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.864\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.590\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.748\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.784\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:10:23\n",
      "INFO:tensorflow:Saving dict for global step 24989: DetectionBoxes_Precision/mAP = 0.7446748, DetectionBoxes_Precision/mAP (large) = 0.8131541, DetectionBoxes_Precision/mAP (medium) = 0.7482075, DetectionBoxes_Precision/mAP (small) = 0.59019333, DetectionBoxes_Precision/mAP@.50IOU = 0.95519453, DetectionBoxes_Precision/mAP@.75IOU = 0.8643052, DetectionBoxes_Recall/AR@1 = 0.7785714, DetectionBoxes_Recall/AR@10 = 0.7785714, DetectionBoxes_Recall/AR@100 = 0.7785714, DetectionBoxes_Recall/AR@100 (large) = 0.8375, DetectionBoxes_Recall/AR@100 (medium) = 0.7842105, DetectionBoxes_Recall/AR@100 (small) = 0.62857145, Loss/classification_loss = 1.6088853, Loss/localization_loss = 0.37177408, Loss/regularization_loss = 0.27278414, Loss/total_loss = 2.2534435, global_step = 24989, learning_rate = 0.004, loss = 2.2534435\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24989: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24989\n",
      "INFO:tensorflow:global_step/sec: 1.02692\n",
      "INFO:tensorflow:loss = 1.0248054, step = 25000 (97.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57943\n",
      "INFO:tensorflow:loss = 0.89895195, step = 25100 (63.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57042\n",
      "INFO:tensorflow:loss = 0.83390296, step = 25200 (63.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57067\n",
      "INFO:tensorflow:loss = 0.8476748, step = 25300 (63.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57555\n",
      "INFO:tensorflow:loss = 0.74731374, step = 25400 (63.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54875\n",
      "INFO:tensorflow:loss = 0.7604755, step = 25500 (64.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55562\n",
      "INFO:tensorflow:loss = 1.02278, step = 25600 (64.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56099\n",
      "INFO:tensorflow:loss = 0.77244276, step = 25700 (64.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5395\n",
      "INFO:tensorflow:loss = 0.97929126, step = 25800 (64.910 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25875 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:20:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-25875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.623\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:20:24\n",
      "INFO:tensorflow:Saving dict for global step 25875: DetectionBoxes_Precision/mAP = 0.7394448, DetectionBoxes_Precision/mAP (large) = 0.7797261, DetectionBoxes_Precision/mAP (medium) = 0.7521775, DetectionBoxes_Precision/mAP (small) = 0.6232815, DetectionBoxes_Precision/mAP@.50IOU = 0.9622499, DetectionBoxes_Precision/mAP@.75IOU = 0.90416056, DetectionBoxes_Recall/AR@1 = 0.77380955, DetectionBoxes_Recall/AR@10 = 0.77380955, DetectionBoxes_Recall/AR@100 = 0.77380955, DetectionBoxes_Recall/AR@100 (large) = 0.81875, DetectionBoxes_Recall/AR@100 (medium) = 0.7736842, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.4879309, Loss/localization_loss = 0.33437285, Loss/regularization_loss = 0.2726813, Loss/total_loss = 2.0949852, global_step = 25875, learning_rate = 0.004, loss = 2.0949852\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25875: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-25875\n",
      "INFO:tensorflow:global_step/sec: 1.02232\n",
      "INFO:tensorflow:loss = 0.6737645, step = 25900 (97.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57384\n",
      "INFO:tensorflow:loss = 0.825817, step = 26000 (63.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57141\n",
      "INFO:tensorflow:loss = 1.3746493, step = 26100 (63.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56939\n",
      "INFO:tensorflow:loss = 1.046996, step = 26200 (63.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56651\n",
      "INFO:tensorflow:loss = 0.654708, step = 26300 (63.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56868\n",
      "INFO:tensorflow:loss = 0.5932985, step = 26400 (63.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57522\n",
      "INFO:tensorflow:loss = 0.88954806, step = 26500 (63.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56382\n",
      "INFO:tensorflow:loss = 0.65953696, step = 26600 (63.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56026\n",
      "INFO:tensorflow:loss = 0.9659239, step = 26700 (64.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26763 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.2361\n",
      "INFO:tensorflow:loss = 0.78418833, step = 26800 (80.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56845\n",
      "INFO:tensorflow:loss = 0.7976807, step = 26900 (63.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5689\n",
      "INFO:tensorflow:loss = 0.8853276, step = 27000 (63.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57166\n",
      "INFO:tensorflow:loss = 0.6431623, step = 27100 (63.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5687\n",
      "INFO:tensorflow:loss = 0.8535866, step = 27200 (63.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56774\n",
      "INFO:tensorflow:loss = 1.4721314, step = 27300 (63.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54789\n",
      "INFO:tensorflow:loss = 0.86394846, step = 27400 (64.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.816526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8492899, step = 27500 (122.550 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27584 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:40:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-27584\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.884\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.742\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.763\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:40:30\n",
      "INFO:tensorflow:Saving dict for global step 27584: DetectionBoxes_Precision/mAP = 0.72967446, DetectionBoxes_Precision/mAP (large) = 0.79412615, DetectionBoxes_Precision/mAP (medium) = 0.7418968, DetectionBoxes_Precision/mAP (small) = 0.55263555, DetectionBoxes_Precision/mAP@.50IOU = 0.96707344, DetectionBoxes_Precision/mAP@.75IOU = 0.8836256, DetectionBoxes_Recall/AR@1 = 0.7595238, DetectionBoxes_Recall/AR@10 = 0.7595238, DetectionBoxes_Recall/AR@100 = 0.7595238, DetectionBoxes_Recall/AR@100 (large) = 0.825, DetectionBoxes_Recall/AR@100 (medium) = 0.7631579, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 1.5778269, Loss/localization_loss = 0.3987388, Loss/regularization_loss = 0.2724136, Loss/total_loss = 2.2489796, global_step = 27584, learning_rate = 0.004, loss = 2.2489796\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 27584: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-27584\n",
      "INFO:tensorflow:global_step/sec: 0.969073\n",
      "INFO:tensorflow:loss = 0.97856426, step = 27600 (103.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57075\n",
      "INFO:tensorflow:loss = 0.85057807, step = 27700 (63.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56568\n",
      "INFO:tensorflow:loss = 0.85169435, step = 27800 (63.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55214\n",
      "INFO:tensorflow:loss = 0.8647555, step = 27900 (64.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55465\n",
      "INFO:tensorflow:loss = 1.1403918, step = 28000 (64.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56563\n",
      "INFO:tensorflow:loss = 0.74429053, step = 28100 (63.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56855\n",
      "INFO:tensorflow:loss = 0.7892519, step = 28200 (63.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56597\n",
      "INFO:tensorflow:loss = 1.0428611, step = 28300 (63.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56595\n",
      "INFO:tensorflow:loss = 0.7763058, step = 28400 (63.824 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28461 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.2478\n",
      "INFO:tensorflow:loss = 0.9285017, step = 28500 (80.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5688\n",
      "INFO:tensorflow:loss = 0.95117974, step = 28600 (63.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57208\n",
      "INFO:tensorflow:loss = 1.6029934, step = 28700 (63.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5706\n",
      "INFO:tensorflow:loss = 0.9239406, step = 28800 (63.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55342\n",
      "INFO:tensorflow:loss = 0.7504623, step = 28900 (64.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5298\n",
      "INFO:tensorflow:loss = 0.715567, step = 29000 (65.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54104\n",
      "INFO:tensorflow:loss = 0.83189934, step = 29100 (64.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54932\n",
      "INFO:tensorflow:loss = 0.744079, step = 29200 (64.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56671\n",
      "INFO:tensorflow:loss = 0.8160756, step = 29300 (63.856 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29371 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T17:00:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-29371\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.862\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.604\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.810\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.783\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.783\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.783\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-17:00:25\n",
      "INFO:tensorflow:Saving dict for global step 29371: DetectionBoxes_Precision/mAP = 0.7448027, DetectionBoxes_Precision/mAP (large) = 0.8097446, DetectionBoxes_Precision/mAP (medium) = 0.7383433, DetectionBoxes_Precision/mAP (small) = 0.60432816, DetectionBoxes_Precision/mAP@.50IOU = 0.964068, DetectionBoxes_Precision/mAP@.75IOU = 0.8618594, DetectionBoxes_Recall/AR@1 = 0.78333336, DetectionBoxes_Recall/AR@10 = 0.78333336, DetectionBoxes_Recall/AR@100 = 0.78333336, DetectionBoxes_Recall/AR@100 (large) = 0.8375, DetectionBoxes_Recall/AR@100 (medium) = 0.77894735, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.5246183, Loss/localization_loss = 0.31559148, Loss/regularization_loss = 0.27221936, Loss/total_loss = 2.1124291, global_step = 29371, learning_rate = 0.004, loss = 2.1124291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 29371: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-29371\n",
      "INFO:tensorflow:global_step/sec: 1.02495\n",
      "INFO:tensorflow:loss = 0.528726, step = 29400 (97.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57597\n",
      "INFO:tensorflow:loss = 0.7492744, step = 29500 (63.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55337\n",
      "INFO:tensorflow:loss = 1.0234061, step = 29600 (64.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56954\n",
      "INFO:tensorflow:loss = 0.807192, step = 29700 (63.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57077\n",
      "INFO:tensorflow:loss = 1.0505508, step = 29800 (63.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57438\n",
      "INFO:tensorflow:loss = 1.1056459, step = 29900 (63.549 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T17:07:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.616\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.746\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.793\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.793\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.793\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.784\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-17:07:39\n",
      "INFO:tensorflow:Saving dict for global step 30000: DetectionBoxes_Precision/mAP = 0.7557675, DetectionBoxes_Precision/mAP (large) = 0.81890833, DetectionBoxes_Precision/mAP (medium) = 0.746374, DetectionBoxes_Precision/mAP (small) = 0.61584157, DetectionBoxes_Precision/mAP@.50IOU = 0.9634329, DetectionBoxes_Precision/mAP@.75IOU = 0.85867894, DetectionBoxes_Recall/AR@1 = 0.79285717, DetectionBoxes_Recall/AR@10 = 0.79285717, DetectionBoxes_Recall/AR@100 = 0.79285717, DetectionBoxes_Recall/AR@100 (large) = 0.85, DetectionBoxes_Recall/AR@100 (medium) = 0.7842105, DetectionBoxes_Recall/AR@100 (small) = 0.6857143, Loss/classification_loss = 1.6269366, Loss/localization_loss = 0.32733673, Loss/regularization_loss = 0.27213073, Loss/total_loss = 2.2264037, global_step = 30000, learning_rate = 0.004, loss = 2.2264037\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-30000\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a directory: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\export\\Servo\\temp-b'1584551259'; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\model_main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\model_main.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m# Currently only a single Eval Spec is allowed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    609\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    610\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;31m# Distributed case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1406\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m         \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m       logging.warning('Training with estimator made no steps. '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m     \u001b[1;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[1;34m(self, exception_type)\u001b[0m\n\u001b[0;32m    819\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m           \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36mend\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listeners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m       \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mend\u001b[1;34m(self, session, global_step_value)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mglobal_step_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, global_step_value)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     self.eval_result, self.export_results = (\n\u001b[1;32m--> 537\u001b[1;33m         self._evaluator.evaluate_and_export())\n\u001b[0m\u001b[0;32m    538\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_EvalStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVALUATED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m       \u001b[1;31m#  This is unexpected; should never happen.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mevaluate_and_export\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    923\u001b[0m           self._max_training_steps if self._max_training_steps else False)\n\u001b[0;32m    924\u001b[0m       export_results = self._export_eval_result(eval_result,\n\u001b[1;32m--> 925\u001b[1;33m                                                 is_the_final_export)\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mis_the_final_export\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36m_export_eval_result\u001b[1;34m(self, eval_result, is_the_final_export)\u001b[0m\n\u001b[0;32m    956\u001b[0m                 \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m                 \u001b[0meval_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m                 is_the_final_export=is_the_final_export))\n\u001b[0m\u001b[0;32m    959\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mexport_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\exporter.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, estimator, export_path, checkpoint_path, eval_result, is_the_final_export)\u001b[0m\n\u001b[0;32m    417\u001b[0m     return self._saved_model_exporter.export(estimator, export_path,\n\u001b[0;32m    418\u001b[0m                                              \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m                                              is_the_final_export)\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\exporter.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         strip_default_attrs=self._strip_default_attrs)\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mexport_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mexport_savedmodel\u001b[1;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m         experimental_mode=model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   def export_saved_model(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mexport_saved_model\u001b[1;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[0massets_extra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0massets_extra\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m   def experimental_export_all_saved_models(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mexperimental_export_all_saved_models\u001b[1;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path)\u001b[0m\n\u001b[0;32m    804\u001b[0m       \u001b[0mtemp_export_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_temp_export_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m       \u001b[0mbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_model_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_export_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m       \u001b[0msave_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, export_dir)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_add_collections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massets_collection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, export_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m           \"directory: %s\" % export_dir)\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m# Boolean to track whether variables and assets corresponding to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \"\"\"\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\export\\Servo\\temp-b'1584551259'; No such file or directory"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'called'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d2b245149de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_main.py --pipeline_config_path={PIPELINE_CONFING_FILEPATH} --model_dir={CHECKPOINTS_DIR}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2317\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    825\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m                         \u001b[1;31m# regular execution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m                         \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'i'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    811\u001b[0m                         \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                             runner(filename, prog_ns, prog_ns,\n\u001b[1;32m--> 813\u001b[1;33m                                     exit_ignore=exit_ignore)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;34m't'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mmpl_execfile\u001b[1;34m(fname, *where, **kw)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# make rendering call now, if the user tried to do it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'called'"
     ]
    }
   ],
   "source": [
    "%run model_main.py --pipeline_config_path={PIPELINE_CONFING_FILEPATH} --model_dir={CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Finetuned Model\n",
    "If the training is finished, the model must be exported so that it can be used.\n",
    "\n",
    "Set CHECKPOINT_NO = 'XXX' where XXX is the number of the last checkpoint file in CHECKPOINTS_DIR, before you start the export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Inputs..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:301: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/2.99m params)\n",
      "  BoxPredictor_0 (--/20.75k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/5.18k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/3.46k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n",
      "    BoxPredictor_0/ClassPredictor_depthwise (--/5.18k params)\n",
      "      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "  BoxPredictor_1 (--/69.16k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/11.52k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x1280x1, 11.52k/11.52k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/15.37k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n",
      "    BoxPredictor_1/ClassPredictor_depthwise (--/11.52k params)\n",
      "      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x1280x1, 11.52k/11.52k params)\n",
      "  BoxPredictor_2 (--/27.68k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
      "    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n",
      "      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "  BoxPredictor_3 (--/13.86k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
      "    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n",
      "      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "  BoxPredictor_4 (--/13.86k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "2020-03-18 18:08:13.671322: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-18 18:08:13.821694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.83\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 8.00GiB freeMemory: 6.59GiB\n",
      "2020-03-18 18:08:13.822017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-18 18:08:16.102109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 18:08:16.102377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-18 18:08:16.102553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-18 18:08:16.103064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6317 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "162 ops no flops stats due to incomplete shapes.\n",
      "162 ops no flops stats due to incomplete shapes.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-03-18 18:08:25.401556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-18 18:08:25.403614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 18:08:25.403800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-18 18:08:25.403911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-18 18:08:25.404144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6317 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "2020-03-18 18:08:27.583729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-18 18:08:27.584010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 18:08:27.584201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-18 18:08:27.584320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-18 18:08:27.584503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6317 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
      "    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n",
      "      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "  BoxPredictor_5 (--/6.95k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
      "    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n",
      "      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
      "      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "  FeatureExtractor (--/2.84m params)\n",
      "    FeatureExtractor/MobilenetV2 (--/2.84m params)\n",
      "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
      "\n",
      "======================End of Report==========================\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/17.62k flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
      "  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/add (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/add (1/1 flops)\n",
      "  Preprocessor/map/while/add_1 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_NO = 30000\n",
    "\n",
    "!python export_inference_graph.py --pipeline_config_path={PIPELINE_CONFING_FILEPATH} --trained_checkpoint_prefix={CHECKPOINTS_DIR}/model.ckpt-{CHECKPOINT_NO} --output_directory={FINETUNED_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Traffic Light Detection\n",
    "\n",
    "Uses the fine tuned traffic light detection model FINETUNED_MODEL_DIR to detect traffic lights in images.\n",
    "\n",
    "#### Load the (frozen) finetuned model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading label map\n",
    "Loads the label map file PATH_TO_LABELS. This file contains a map that assigns category names to the class-indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"GER\"\n",
      "  id: 1\n",
      "}\n",
      "\n",
      "[{'id': 1, 'name': 'GER'}]\n",
      "{1: {'id': 1, 'name': 'GER'}}\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "print (label_map)\n",
    "print (categories)\n",
    "print (category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 test images found in ../../data/plate_detection/test_images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e05e3b59e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '../../data/plate_detection/test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = []\n",
    "for filename in glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg')):\n",
    "    TEST_IMAGE_PATHS.append(filename)\n",
    "    \n",
    "print ('{} test images found in {}'.format(len(TEST_IMAGE_PATHS), PATH_TO_TEST_IMAGES_DIR))\n",
    "\n",
    "plt.imshow(mpimg.imread(TEST_IMAGE_PATHS[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# number of samples to test; -1 <=> all\n",
    "NUM_SAMPLES = 2\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 12)\n",
    "\n",
    "if NUM_SAMPLES > 0:\n",
    "    test_images = np.random.choice(TEST_IMAGE_PATHS, size = NUM_SAMPLES, replace=False)\n",
    "else:\n",
    "    test_images = TEST_IMAGE_PATHS\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for image_path in test_images:\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=4)\n",
    "            plt.figure(figsize=IMAGE_SIZE)\n",
    "            plt.title(image_path)\n",
    "            plt.imshow(image_np)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py:61: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n",
      "INFO:tensorflow:input tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: inputs\n",
      "INFO:tensorflow: tensor name: image_tensor:0, shape: (-1, -1, -1, 3), type: DT_UINT8\n",
      "INFO:tensorflow:output tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_boxes\n",
      "INFO:tensorflow: tensor name: detection_boxes:0, shape: (-1, 10, 4), type: DT_FLOAT\n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_scores\n",
      "INFO:tensorflow: tensor name: detection_scores:0, shape: (-1, 10), type: DT_FLOAT\n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_classes\n",
      "INFO:tensorflow: tensor name: detection_classes:0, shape: (-1, 10), type: DT_FLOAT\n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: num_detections\n",
      "INFO:tensorflow: tensor name: num_detections:0, shape: (-1), type: DT_FLOAT\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py:275: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "INFO:tensorflow:Converted 0 variables to const ops.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-dc17b65c6a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFINETUNED_MODEL_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/saved_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#converter.optimizations=[Optimize.DEFAULT]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFLITE_MODEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m           raise ValueError(\n\u001b[0;32m    410\u001b[0m               \u001b[1;34m\"None is only supported in the 1st dimension. Tensor '{0}' has \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m               \"invalid shape '{1}'.\".format(_tensor_name(tensor), shape_list))\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'."
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.lite import TFLiteConverter #, Optimize\n",
    "\n",
    "input_arrays=[\"image_tensor\"]\n",
    "output_arrays=[\"detection_boxes\",\"detection_scores\",\"num_detections\",\"detection_classes\"]\n",
    "input_tensor={\"image_tensor\":[1,300,300,3]}\n",
    "\n",
    "#converter = TFLiteConverter.from_frozen_graph(PATH_TO_FROZEN_GRAPH, input_arrays, output_arrays, input_tensor)\n",
    "converter = TFLiteConverter.from_saved_model(FINETUNED_MODEL_DIR + '/saved_model')\n",
    "#converter.optimizations=[Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(TFLITE_MODEL_PATH, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provided has model identifier 'Cons', should be 'TFL3'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-52b4add94701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load TFLite model and allocate tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPATH_TO_FROZEN_GRAPH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get input and output tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content)\u001b[0m\n\u001b[0;32m     53\u001b[0m       self._interpreter = (\n\u001b[0;32m     54\u001b[0m           _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\n\u001b[1;32m---> 55\u001b[1;33m               model_path))\n\u001b[0m\u001b[0;32m     56\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to open {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Model provided has model identifier 'Cons', should be 'TFL3'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.lite import Interpreter\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = Interpreter(model_path=PATH_TO_FROZEN_GRAPH)\n",
    "interpreter.allocate_tensors()\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "# Test model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "print(\"Input Shape:  {}\".format(input_shape))\n",
    "print(\"Input Details: {}\".format(input_details))\n",
    "print(\"Output Details: {}\".format(output_details))\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Output: {}\".format(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
