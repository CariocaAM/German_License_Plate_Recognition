{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detection - Data Collection and Exploration\n",
    "Welcome to the traffic light detection! This notebook explains step-by-step how to train and use license plate detection models for the Machine Learning Engineer Capstone Project. Make sure you meet all preconditions before you start, see README.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import matplotlib\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Tensorflow version..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 1.13.1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print (\"Tensorflow: {}\".format(tf.__version__))\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.13.1'):\n",
    "    raise ImportError('Please upgrade your TensorFlow installation to v1.13.1')\n",
    "\n",
    "if StrictVersion(tf.__version__) >= StrictVersion('2.0.0'):\n",
    "    raise ImportError('Please downgrade your TensorFlow installation to v1.13.*.')\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images inside the notebook cells.\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'tf_object_detection'))\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(working_dir)\n",
    "sys.path.append(working_dir + \"/slim\")\n",
    "\n",
    "path = working_dir + ';' + working_dir + '/slim' + ';' + working_dir + '/object_detection'\n",
    "os.environ['PYTHONPATH'] = path\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'object_detection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation\n",
    "\n",
    "#### Variables\n",
    "Define the pretrained model to be used.\n",
    "Change MODEL and PIPELINE_CONFING_FILENAME if you want to use other pretrained models, see the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pretrained model\n",
    "MODEL = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "PIPELINE_CONFING_FILENAME = 'ssdlite_mobilenet_v2_coco.config'\n",
    "\n",
    "#MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "#PIPELINE_CONFING_FILENAME = 'ssd_mobilenet_v2.config'\n",
    "\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels file:           ../../config/plate_detection\\labels_map.pbtxt\n",
      "Pipeline config file:  ../../config/plate_detection\\ssdlite_mobilenet_v2_coco.config\n",
      "Checkpoints directory: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\n",
      "Frozen model file:     ../../output/plate_detection/fine_tuned_models/ssdlite_mobilenet_v2_coco_2018_05_09\\frozen_inference_graph.pb\n",
      "TFLite model file:     ../../output/plate_detection\\glpd-model-float.tflite\n"
     ]
    }
   ],
   "source": [
    "# ****************** don't edit ******************\n",
    "\n",
    "# What model to download.\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "PRETRAIND_MODELS_DIR = 'models'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "DETECTION_COFIG_DIR = '../../config/plate_detection'\n",
    "PATH_TO_LABELS = os.path.join(DETECTION_COFIG_DIR, 'labels_map.pbtxt')\n",
    "\n",
    "PIPELINE_CONFING_FILEPATH = os.path.join(DETECTION_COFIG_DIR, PIPELINE_CONFING_FILENAME)\n",
    "\n",
    "OUTPUT_DIR = '../../output/plate_detection'\n",
    "CHECKPOINTS_DIR = OUTPUT_DIR + '/checkpoints/' + MODEL\n",
    "FINETUNED_MODEL_DIR = OUTPUT_DIR + '/fine_tuned_models/' + MODEL\n",
    "\n",
    "# Path to frozen detection graph.\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(FINETUNED_MODEL_DIR, 'frozen_inference_graph.pb')\n",
    "\n",
    "TFLITE_MODEL_PATH = os.path.join(OUTPUT_DIR, 'glpd-model-float.tflite')\n",
    "\n",
    "print ('Labels file:           {}'.format(PATH_TO_LABELS))\n",
    "print ('Pipeline config file:  {}'.format(PIPELINE_CONFING_FILEPATH))\n",
    "print ('Checkpoints directory: {}'.format(CHECKPOINTS_DIR))\n",
    "print ('Frozen model file:     {}'.format(PATH_TO_FROZEN_GRAPH))\n",
    "print ('TFLite model file:     {}'.format(TFLITE_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Traffic Light Detection Model\n",
    "\n",
    "**NOTE:** If you have already trained the model, you can skip the training- and export steps and proceed directly with testing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Pretrained Model\n",
    "\n",
    "**NOTE:** This step only needs to be done once if the pretrained model has not been downloaded yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ZIP = os.path.join(PRETRAIND_MODELS_DIR, MODEL_FILE)\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_ZIP)\n",
    "tar_file = tarfile.open(MODEL_ZIP)\n",
    "tar_file.extractall(os.path.join(os.getcwd(), PRETRAIND_MODELS_DIR))\n",
    "tar_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Finetuned Model\n",
    "\n",
    "Starts the training. This step may take several hours, depending on the computing power of your computer.\n",
    "You can monitor the training process using tensorboard tensorboard --logdir=%CHECKPOINTS_DIR% and stop the training if once the desired accuracy has been achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E0290984E0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001E02908EE18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\builders\\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\utils\\ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\inputs.py:287: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\core\\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\core\\preprocessor.py:1218: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\builders\\dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:loss = 11.053393, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.45366\n",
      "INFO:tensorflow:loss = 4.7770586, step = 100 (68.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56673\n",
      "INFO:tensorflow:loss = 2.7802205, step = 200 (63.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57968\n",
      "INFO:tensorflow:loss = 2.9189224, step = 300 (63.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58408\n",
      "INFO:tensorflow:loss = 3.1690025, step = 400 (63.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59038\n",
      "INFO:tensorflow:loss = 2.2350316, step = 500 (62.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59258\n",
      "INFO:tensorflow:loss = 1.9185493, step = 600 (62.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58667\n",
      "INFO:tensorflow:loss = 2.248416, step = 700 (63.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59\n",
      "INFO:tensorflow:loss = 2.7644389, step = 800 (62.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58715\n",
      "INFO:tensorflow:loss = 1.4865445, step = 900 (63.044 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 929 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\object_detection-0.1-py3.6.egg\\object_detection\\utils\\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:09:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-929\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.581\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:09:39\n",
      "INFO:tensorflow:Saving dict for global step 929: DetectionBoxes_Precision/mAP = 0.21955995, DetectionBoxes_Precision/mAP (large) = 0.24938384, DetectionBoxes_Precision/mAP (medium) = 0.27906442, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.58072233, DetectionBoxes_Precision/mAP@.75IOU = 0.06766815, DetectionBoxes_Recall/AR@1 = 0.24761905, DetectionBoxes_Recall/AR@10 = 0.26190478, DetectionBoxes_Recall/AR@100 = 0.26190478, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = 0.29473683, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 4.7069907, Loss/localization_loss = 2.5767212, Loss/regularization_loss = 0.26792714, Loss/total_loss = 7.5516386, global_step = 929, learning_rate = 0.004, loss = 7.5516386\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 929: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-929\n",
      "INFO:tensorflow:global_step/sec: 0.980704\n",
      "INFO:tensorflow:loss = 2.3349867, step = 1000 (101.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58486\n",
      "INFO:tensorflow:loss = 1.5575612, step = 1100 (63.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55267\n",
      "INFO:tensorflow:loss = 1.8884404, step = 1200 (64.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55145\n",
      "INFO:tensorflow:loss = 1.76633, step = 1300 (64.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54181\n",
      "INFO:tensorflow:loss = 1.4611709, step = 1400 (64.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56986\n",
      "INFO:tensorflow:loss = 1.3394883, step = 1500 (63.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55698\n",
      "INFO:tensorflow:loss = 2.5255833, step = 1600 (64.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56814\n",
      "INFO:tensorflow:loss = 1.1828951, step = 1700 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55894\n",
      "INFO:tensorflow:loss = 1.4629807, step = 1800 (64.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1806 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:19:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-1806\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.589\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:19:41\n",
      "INFO:tensorflow:Saving dict for global step 1806: DetectionBoxes_Precision/mAP = 0.21670584, DetectionBoxes_Precision/mAP (large) = 0.2506739, DetectionBoxes_Precision/mAP (medium) = 0.272684, DetectionBoxes_Precision/mAP (small) = 0.004950495, DetectionBoxes_Precision/mAP@.50IOU = 0.58866036, DetectionBoxes_Precision/mAP@.75IOU = 0.03570357, DetectionBoxes_Recall/AR@1 = 0.23571429, DetectionBoxes_Recall/AR@10 = 0.26904762, DetectionBoxes_Recall/AR@100 = 0.26904762, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = 0.31578946, DetectionBoxes_Recall/AR@100 (small) = 0.014285714, Loss/classification_loss = 4.9176683, Loss/localization_loss = 2.4751089, Loss/regularization_loss = 0.26894596, Loss/total_loss = 7.6617227, global_step = 1806, learning_rate = 0.004, loss = 7.6617227\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1806: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-1806\n",
      "INFO:tensorflow:global_step/sec: 1.02071\n",
      "INFO:tensorflow:loss = 1.4980515, step = 1900 (98.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56492\n",
      "INFO:tensorflow:loss = 1.6271307, step = 2000 (63.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5751\n",
      "INFO:tensorflow:loss = 1.0337682, step = 2100 (63.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57272\n",
      "INFO:tensorflow:loss = 2.350081, step = 2200 (63.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55831\n",
      "INFO:tensorflow:loss = 1.8033535, step = 2300 (64.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56998\n",
      "INFO:tensorflow:loss = 1.5622387, step = 2400 (63.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57876\n",
      "INFO:tensorflow:loss = 2.3688521, step = 2500 (63.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54909\n",
      "INFO:tensorflow:loss = 1.2500135, step = 2600 (64.510 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2692 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.2364\n",
      "INFO:tensorflow:loss = 1.1001835, step = 2700 (80.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57896\n",
      "INFO:tensorflow:loss = 1.209598, step = 2800 (63.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57003\n",
      "INFO:tensorflow:loss = 1.8806893, step = 2900 (63.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57265\n",
      "INFO:tensorflow:loss = 1.4885614, step = 3000 (63.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57075\n",
      "INFO:tensorflow:loss = 1.107662, step = 3100 (63.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 1.7617247, step = 3200 (63.572 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.56433\n",
      "INFO:tensorflow:loss = 1.1049042, step = 3300 (63.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57292\n",
      "INFO:tensorflow:loss = 1.3004199, step = 3400 (63.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55393\n",
      "INFO:tensorflow:loss = 1.5349876, step = 3500 (64.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54842\n",
      "INFO:tensorflow:loss = 1.0030417, step = 3600 (64.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3607 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:39:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-3607\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:39:42\n",
      "INFO:tensorflow:Saving dict for global step 3607: DetectionBoxes_Precision/mAP = 0.25504938, DetectionBoxes_Precision/mAP (large) = 0.27252045, DetectionBoxes_Precision/mAP (medium) = 0.31691545, DetectionBoxes_Precision/mAP (small) = 0.18811882, DetectionBoxes_Precision/mAP@.50IOU = 0.62265885, DetectionBoxes_Precision/mAP@.75IOU = 0.069464415, DetectionBoxes_Recall/AR@1 = 0.2809524, DetectionBoxes_Recall/AR@10 = 0.32142857, DetectionBoxes_Recall/AR@100 = 0.32142857, DetectionBoxes_Recall/AR@100 (large) = 0.35625, DetectionBoxes_Recall/AR@100 (medium) = 0.34210527, DetectionBoxes_Recall/AR@100 (small) = 0.18571429, Loss/classification_loss = 4.609881, Loss/localization_loss = 2.3032577, Loss/regularization_loss = 0.2703162, Loss/total_loss = 7.183454, global_step = 3607, learning_rate = 0.004, loss = 7.183454\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3607: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-3607\n",
      "INFO:tensorflow:global_step/sec: 1.00377\n",
      "INFO:tensorflow:loss = 1.5041399, step = 3700 (99.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54668\n",
      "INFO:tensorflow:loss = 1.3290677, step = 3800 (64.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57364\n",
      "INFO:tensorflow:loss = 1.0991906, step = 3900 (63.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57201\n",
      "INFO:tensorflow:loss = 1.9540477, step = 4000 (63.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55468\n",
      "INFO:tensorflow:loss = 1.1397275, step = 4100 (64.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5724\n",
      "INFO:tensorflow:loss = 1.2353792, step = 4200 (63.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57525\n",
      "INFO:tensorflow:loss = 1.9099083, step = 4300 (63.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58015\n",
      "INFO:tensorflow:loss = 1.2401619, step = 4400 (63.238 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4493 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.13\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:49:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-4493\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:49:41\n",
      "INFO:tensorflow:Saving dict for global step 4493: DetectionBoxes_Precision/mAP = 0.25252178, DetectionBoxes_Precision/mAP (large) = 0.2842914, DetectionBoxes_Precision/mAP (medium) = 0.30819568, DetectionBoxes_Precision/mAP (small) = 0.12143564, DetectionBoxes_Precision/mAP@.50IOU = 0.59457046, DetectionBoxes_Precision/mAP@.75IOU = 0.0893063, DetectionBoxes_Recall/AR@1 = 0.27857143, DetectionBoxes_Recall/AR@10 = 0.33095238, DetectionBoxes_Recall/AR@100 = 0.33095238, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = 0.34736842, DetectionBoxes_Recall/AR@100 (small) = 0.21428572, Loss/classification_loss = 4.8375907, Loss/localization_loss = 2.1584802, Loss/regularization_loss = 0.27083874, Loss/total_loss = 7.266911, global_step = 4493, learning_rate = 0.004, loss = 7.266911\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4493: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-4493\n",
      "INFO:tensorflow:global_step/sec: 1.03365\n",
      "INFO:tensorflow:loss = 1.1504732, step = 4500 (96.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58113\n",
      "INFO:tensorflow:loss = 1.596603, step = 4600 (63.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1421664, step = 4700 (63.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55024\n",
      "INFO:tensorflow:loss = 1.7200829, step = 4800 (64.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57508\n",
      "INFO:tensorflow:loss = 1.3275857, step = 4900 (63.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56178\n",
      "INFO:tensorflow:loss = 1.25367, step = 5000 (63.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56199\n",
      "INFO:tensorflow:loss = 1.2727109, step = 5100 (64.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56502\n",
      "INFO:tensorflow:loss = 1.1996188, step = 5200 (63.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56688\n",
      "INFO:tensorflow:loss = 0.9918119, step = 5300 (63.863 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5381 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T11:59:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-5381\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-11:59:42\n",
      "INFO:tensorflow:Saving dict for global step 5381: DetectionBoxes_Precision/mAP = 0.27836335, DetectionBoxes_Precision/mAP (large) = 0.31867683, DetectionBoxes_Precision/mAP (medium) = 0.3134803, DetectionBoxes_Precision/mAP (small) = 0.22227722, DetectionBoxes_Precision/mAP@.50IOU = 0.71754545, DetectionBoxes_Precision/mAP@.75IOU = 0.09156141, DetectionBoxes_Recall/AR@1 = 0.30714285, DetectionBoxes_Recall/AR@10 = 0.37142858, DetectionBoxes_Recall/AR@100 = 0.37142858, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.36842105, DetectionBoxes_Recall/AR@100 (small) = 0.3, Loss/classification_loss = 4.0200434, Loss/localization_loss = 2.047714, Loss/regularization_loss = 0.27120948, Loss/total_loss = 6.338967, global_step = 5381, learning_rate = 0.004, loss = 6.338967\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5381: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-5381\n",
      "INFO:tensorflow:global_step/sec: 1.02757\n",
      "INFO:tensorflow:loss = 1.0050988, step = 5400 (97.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55826\n",
      "INFO:tensorflow:loss = 0.92588156, step = 5500 (64.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57493\n",
      "INFO:tensorflow:loss = 1.3314233, step = 5600 (63.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56924\n",
      "INFO:tensorflow:loss = 0.94624555, step = 5700 (63.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56548\n",
      "INFO:tensorflow:loss = 1.1352828, step = 5800 (63.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56902\n",
      "INFO:tensorflow:loss = 0.9881964, step = 5900 (63.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5713\n",
      "INFO:tensorflow:loss = 1.1309838, step = 6000 (63.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55458\n",
      "INFO:tensorflow:loss = 1.2333928, step = 6100 (64.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56779\n",
      "INFO:tensorflow:loss = 1.1549134, step = 6200 (63.737 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6269 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:09:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-6269\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:09:42\n",
      "INFO:tensorflow:Saving dict for global step 6269: DetectionBoxes_Precision/mAP = 0.2884612, DetectionBoxes_Precision/mAP (large) = 0.29693156, DetectionBoxes_Precision/mAP (medium) = 0.34050855, DetectionBoxes_Precision/mAP (small) = 0.28638613, DetectionBoxes_Precision/mAP@.50IOU = 0.71921694, DetectionBoxes_Precision/mAP@.75IOU = 0.09614697, DetectionBoxes_Recall/AR@1 = 0.33333334, DetectionBoxes_Recall/AR@10 = 0.38809523, DetectionBoxes_Recall/AR@100 = 0.38809523, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.38947368, DetectionBoxes_Recall/AR@100 (small) = 0.34285715, Loss/classification_loss = 3.9325256, Loss/localization_loss = 1.9067831, Loss/regularization_loss = 0.27157977, Loss/total_loss = 6.110888, global_step = 6269, learning_rate = 0.004, loss = 6.110888\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6269: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-6269\n",
      "INFO:tensorflow:global_step/sec: 1.03151\n",
      "INFO:tensorflow:loss = 1.1578708, step = 6300 (96.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57089\n",
      "INFO:tensorflow:loss = 0.94521916, step = 6400 (63.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0671122, step = 6500 (63.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55647\n",
      "INFO:tensorflow:loss = 1.0933914, step = 6600 (64.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56294\n",
      "INFO:tensorflow:loss = 1.0086803, step = 6700 (64.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58098\n",
      "INFO:tensorflow:loss = 0.91134095, step = 6800 (63.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59223\n",
      "INFO:tensorflow:loss = 1.0346198, step = 6900 (62.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58065\n",
      "INFO:tensorflow:loss = 0.82258916, step = 7000 (63.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58502\n",
      "INFO:tensorflow:loss = 1.151697, step = 7100 (63.147 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7162 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:19:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-7162\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:19:42\n",
      "INFO:tensorflow:Saving dict for global step 7162: DetectionBoxes_Precision/mAP = 0.2887178, DetectionBoxes_Precision/mAP (large) = 0.29356945, DetectionBoxes_Precision/mAP (medium) = 0.35687637, DetectionBoxes_Precision/mAP (small) = 0.21856436, DetectionBoxes_Precision/mAP@.50IOU = 0.6976918, DetectionBoxes_Precision/mAP@.75IOU = 0.14432031, DetectionBoxes_Recall/AR@1 = 0.35, DetectionBoxes_Recall/AR@10 = 0.37380952, DetectionBoxes_Recall/AR@100 = 0.37380952, DetectionBoxes_Recall/AR@100 (large) = 0.40625, DetectionBoxes_Recall/AR@100 (medium) = 0.38421053, DetectionBoxes_Recall/AR@100 (small) = 0.27142859, Loss/classification_loss = 4.5566554, Loss/localization_loss = 1.8952757, Loss/regularization_loss = 0.2718522, Loss/total_loss = 6.7237825, global_step = 7162, learning_rate = 0.004, loss = 6.7237825\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7162: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-7162\n",
      "INFO:tensorflow:global_step/sec: 1.03614\n",
      "INFO:tensorflow:loss = 1.2179914, step = 7200 (96.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59213\n",
      "INFO:tensorflow:loss = 0.87403876, step = 7300 (62.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58745\n",
      "INFO:tensorflow:loss = 1.2556773, step = 7400 (62.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58624\n",
      "INFO:tensorflow:loss = 0.9953369, step = 7500 (63.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58977\n",
      "INFO:tensorflow:loss = 0.9945806, step = 7600 (62.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58864\n",
      "INFO:tensorflow:loss = 1.0065402, step = 7700 (62.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58406\n",
      "INFO:tensorflow:loss = 0.9290036, step = 7800 (63.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59312\n",
      "INFO:tensorflow:loss = 1.2035403, step = 7900 (62.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58524\n",
      "INFO:tensorflow:loss = 0.960917, step = 8000 (63.038 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8063 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:29:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8063\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.777\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:29:43\n",
      "INFO:tensorflow:Saving dict for global step 8063: DetectionBoxes_Precision/mAP = 0.33763, DetectionBoxes_Precision/mAP (large) = 0.38174534, DetectionBoxes_Precision/mAP (medium) = 0.37249666, DetectionBoxes_Precision/mAP (small) = 0.30792078, DetectionBoxes_Precision/mAP@.50IOU = 0.7773255, DetectionBoxes_Precision/mAP@.75IOU = 0.20206332, DetectionBoxes_Recall/AR@1 = 0.3809524, DetectionBoxes_Recall/AR@10 = 0.43333334, DetectionBoxes_Recall/AR@100 = 0.43333334, DetectionBoxes_Recall/AR@100 (large) = 0.45625, DetectionBoxes_Recall/AR@100 (medium) = 0.4368421, DetectionBoxes_Recall/AR@100 (small) = 0.37142858, Loss/classification_loss = 4.0042467, Loss/localization_loss = 1.6922796, Loss/regularization_loss = 0.27210844, Loss/total_loss = 5.968635, global_step = 8063, learning_rate = 0.004, loss = 5.968635\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8063: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8063\n",
      "INFO:tensorflow:global_step/sec: 1.03541\n",
      "INFO:tensorflow:loss = 1.1531446, step = 8100 (96.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58589\n",
      "INFO:tensorflow:loss = 0.8470978, step = 8200 (63.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.91215503, step = 8300 (63.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59297\n",
      "INFO:tensorflow:loss = 1.0126481, step = 8400 (62.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59\n",
      "INFO:tensorflow:loss = 0.9959841, step = 8500 (62.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58597\n",
      "INFO:tensorflow:loss = 0.9886245, step = 8600 (63.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59114\n",
      "INFO:tensorflow:loss = 0.80002624, step = 8700 (62.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5894\n",
      "INFO:tensorflow:loss = 0.93394667, step = 8800 (62.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58418\n",
      "INFO:tensorflow:loss = 1.6092228, step = 8900 (63.168 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8963 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:39:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8963\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:39:43\n",
      "INFO:tensorflow:Saving dict for global step 8963: DetectionBoxes_Precision/mAP = 0.33193263, DetectionBoxes_Precision/mAP (large) = 0.3808868, DetectionBoxes_Precision/mAP (medium) = 0.35935172, DetectionBoxes_Precision/mAP (small) = 0.3049505, DetectionBoxes_Precision/mAP@.50IOU = 0.7654584, DetectionBoxes_Precision/mAP@.75IOU = 0.1754643, DetectionBoxes_Recall/AR@1 = 0.3857143, DetectionBoxes_Recall/AR@10 = 0.44761905, DetectionBoxes_Recall/AR@100 = 0.44761905, DetectionBoxes_Recall/AR@100 (large) = 0.4875, DetectionBoxes_Recall/AR@100 (medium) = 0.4368421, DetectionBoxes_Recall/AR@100 (small) = 0.3857143, Loss/classification_loss = 3.8525648, Loss/localization_loss = 1.5553297, Loss/regularization_loss = 0.27231607, Loss/total_loss = 5.68021, global_step = 8963, learning_rate = 0.004, loss = 5.68021\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8963: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-8963\n",
      "INFO:tensorflow:global_step/sec: 1.04066\n",
      "INFO:tensorflow:loss = 0.9091662, step = 9000 (96.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5863\n",
      "INFO:tensorflow:loss = 0.9809174, step = 9100 (63.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59048\n",
      "INFO:tensorflow:loss = 0.9433055, step = 9200 (62.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58677\n",
      "INFO:tensorflow:loss = 1.4902347, step = 9300 (63.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59213\n",
      "INFO:tensorflow:loss = 1.1695669, step = 9400 (62.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58457\n",
      "INFO:tensorflow:loss = 1.4232985, step = 9500 (63.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5874\n",
      "INFO:tensorflow:loss = 1.0455487, step = 9600 (62.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58793\n",
      "INFO:tensorflow:loss = 1.2096956, step = 9700 (63.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58268\n",
      "INFO:tensorflow:loss = 1.6367497, step = 9800 (63.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9863 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:49:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-9863\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:49:43\n",
      "INFO:tensorflow:Saving dict for global step 9863: DetectionBoxes_Precision/mAP = 0.3601881, DetectionBoxes_Precision/mAP (large) = 0.41168198, DetectionBoxes_Precision/mAP (medium) = 0.38401112, DetectionBoxes_Precision/mAP (small) = 0.36353135, DetectionBoxes_Precision/mAP@.50IOU = 0.7738264, DetectionBoxes_Precision/mAP@.75IOU = 0.24431352, DetectionBoxes_Recall/AR@1 = 0.45238096, DetectionBoxes_Recall/AR@10 = 0.4952381, DetectionBoxes_Recall/AR@100 = 0.4952381, DetectionBoxes_Recall/AR@100 (large) = 0.51875, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = 0.42857143, Loss/classification_loss = 4.119317, Loss/localization_loss = 1.3893025, Loss/regularization_loss = 0.2725325, Loss/total_loss = 5.781152, global_step = 9863, learning_rate = 0.004, loss = 5.781152\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9863: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-9863\n",
      "INFO:tensorflow:global_step/sec: 1.03923\n",
      "INFO:tensorflow:loss = 1.7237545, step = 9900 (96.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58932\n",
      "INFO:tensorflow:loss = 1.4906914, step = 10000 (62.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.77266514, step = 10100 (63.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58695\n",
      "INFO:tensorflow:loss = 0.976238, step = 10200 (62.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58947\n",
      "INFO:tensorflow:loss = 0.7733383, step = 10300 (62.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58584\n",
      "INFO:tensorflow:loss = 1.1590183, step = 10400 (63.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58448\n",
      "INFO:tensorflow:loss = 1.1206701, step = 10500 (63.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58333\n",
      "INFO:tensorflow:loss = 0.85948205, step = 10600 (63.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58043\n",
      "INFO:tensorflow:loss = 0.71612775, step = 10700 (63.317 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10762 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T12:59:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-10762\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.829\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-12:59:45\n",
      "INFO:tensorflow:Saving dict for global step 10762: DetectionBoxes_Precision/mAP = 0.3922996, DetectionBoxes_Precision/mAP (large) = 0.45440143, DetectionBoxes_Precision/mAP (medium) = 0.4020533, DetectionBoxes_Precision/mAP (small) = 0.40965346, DetectionBoxes_Precision/mAP@.50IOU = 0.829103, DetectionBoxes_Precision/mAP@.75IOU = 0.24389522, DetectionBoxes_Recall/AR@1 = 0.4738095, DetectionBoxes_Recall/AR@10 = 0.4904762, DetectionBoxes_Recall/AR@100 = 0.4904762, DetectionBoxes_Recall/AR@100 (large) = 0.525, DetectionBoxes_Recall/AR@100 (medium) = 0.47894737, DetectionBoxes_Recall/AR@100 (small) = 0.44285715, Loss/classification_loss = 3.1704524, Loss/localization_loss = 1.274271, Loss/regularization_loss = 0.2727635, Loss/total_loss = 4.7174873, global_step = 10762, learning_rate = 0.004, loss = 4.7174873\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10762: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-10762\n",
      "INFO:tensorflow:global_step/sec: 1.02207\n",
      "INFO:tensorflow:loss = 1.2882607, step = 10800 (97.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58085\n",
      "INFO:tensorflow:loss = 1.1375971, step = 10900 (63.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48489\n",
      "INFO:tensorflow:loss = 1.6180861, step = 11000 (67.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56561\n",
      "INFO:tensorflow:loss = 0.8557518, step = 11100 (63.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57831\n",
      "INFO:tensorflow:loss = 1.2817976, step = 11200 (63.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5688\n",
      "INFO:tensorflow:loss = 0.96116847, step = 11300 (63.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57938\n",
      "INFO:tensorflow:loss = 1.2490941, step = 11400 (63.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5495\n",
      "INFO:tensorflow:loss = 1.0169579, step = 11500 (64.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55783\n",
      "INFO:tensorflow:loss = 0.85584235, step = 11600 (64.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11644 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.22468\n",
      "INFO:tensorflow:loss = 1.1488913, step = 11700 (81.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47528\n",
      "INFO:tensorflow:loss = 0.9103625, step = 11800 (67.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48467\n",
      "INFO:tensorflow:loss = 0.93949485, step = 11900 (67.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55626\n",
      "INFO:tensorflow:loss = 0.92879784, step = 12000 (64.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53853\n",
      "INFO:tensorflow:loss = 0.93614954, step = 12100 (65.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53117\n",
      "INFO:tensorflow:loss = 0.6210952, step = 12200 (65.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55251\n",
      "INFO:tensorflow:loss = 0.7947601, step = 12300 (64.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56321\n",
      "INFO:tensorflow:loss = 0.96878326, step = 12400 (63.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55886\n",
      "INFO:tensorflow:loss = 0.64113784, step = 12500 (64.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12539 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:19:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-12539\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:19:44\n",
      "INFO:tensorflow:Saving dict for global step 12539: DetectionBoxes_Precision/mAP = 0.49922308, DetectionBoxes_Precision/mAP (large) = 0.5653875, DetectionBoxes_Precision/mAP (medium) = 0.48202696, DetectionBoxes_Precision/mAP (small) = 0.530363, DetectionBoxes_Precision/mAP@.50IOU = 0.89282936, DetectionBoxes_Precision/mAP@.75IOU = 0.43679586, DetectionBoxes_Recall/AR@1 = 0.552381, DetectionBoxes_Recall/AR@10 = 0.58809525, DetectionBoxes_Recall/AR@100 = 0.58809525, DetectionBoxes_Recall/AR@100 (large) = 0.63125, DetectionBoxes_Recall/AR@100 (medium) = 0.55789477, DetectionBoxes_Recall/AR@100 (small) = 0.5714286, Loss/classification_loss = 3.1979833, Loss/localization_loss = 0.98951423, Loss/regularization_loss = 0.27301437, Loss/total_loss = 4.4605117, global_step = 12539, learning_rate = 0.004, loss = 4.4605117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12539: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-12539\n",
      "INFO:tensorflow:global_step/sec: 1.03821\n",
      "INFO:tensorflow:loss = 1.2462051, step = 12600 (96.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56725\n",
      "INFO:tensorflow:loss = 0.8063697, step = 12700 (63.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55241\n",
      "INFO:tensorflow:loss = 1.0532905, step = 12800 (64.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55166\n",
      "INFO:tensorflow:loss = 1.0592431, step = 12900 (64.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52611\n",
      "INFO:tensorflow:loss = 1.080258, step = 13000 (65.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55485\n",
      "INFO:tensorflow:loss = 0.78680813, step = 13100 (64.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49452\n",
      "INFO:tensorflow:loss = 1.3208898, step = 13200 (66.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52253\n",
      "INFO:tensorflow:loss = 1.1211048, step = 13300 (65.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51162\n",
      "INFO:tensorflow:loss = 1.2905009, step = 13400 (66.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13412 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:29:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-13412\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.919\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.576\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:29:46\n",
      "INFO:tensorflow:Saving dict for global step 13412: DetectionBoxes_Precision/mAP = 0.5168004, DetectionBoxes_Precision/mAP (large) = 0.61555976, DetectionBoxes_Precision/mAP (medium) = 0.48324242, DetectionBoxes_Precision/mAP (small) = 0.5061056, DetectionBoxes_Precision/mAP@.50IOU = 0.91946447, DetectionBoxes_Precision/mAP@.75IOU = 0.5446482, DetectionBoxes_Recall/AR@1 = 0.5761905, DetectionBoxes_Recall/AR@10 = 0.59761906, DetectionBoxes_Recall/AR@100 = 0.59761906, DetectionBoxes_Recall/AR@100 (large) = 0.65625, DetectionBoxes_Recall/AR@100 (medium) = 0.56842107, DetectionBoxes_Recall/AR@100 (small) = 0.54285717, Loss/classification_loss = 2.4788606, Loss/localization_loss = 0.88989294, Loss/regularization_loss = 0.27311417, Loss/total_loss = 3.6418679, global_step = 13412, learning_rate = 0.004, loss = 3.6418679\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13412: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-13412\n",
      "INFO:tensorflow:global_step/sec: 1.01785\n",
      "INFO:tensorflow:loss = 0.87178636, step = 13500 (98.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57356\n",
      "INFO:tensorflow:loss = 1.0850344, step = 13600 (63.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57084\n",
      "INFO:tensorflow:loss = 1.0126143, step = 13700 (63.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57314\n",
      "INFO:tensorflow:loss = 1.3520375, step = 13800 (63.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56811\n",
      "INFO:tensorflow:loss = 0.94509256, step = 13900 (63.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55378\n",
      "INFO:tensorflow:loss = 1.1087849, step = 14000 (64.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55265\n",
      "INFO:tensorflow:loss = 1.4385773, step = 14100 (64.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5571\n",
      "INFO:tensorflow:loss = 1.8357592, step = 14200 (64.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14298 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T13:39:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-14298\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.616\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-13:39:47\n",
      "INFO:tensorflow:Saving dict for global step 14298: DetectionBoxes_Precision/mAP = 0.5614403, DetectionBoxes_Precision/mAP (large) = 0.6475208, DetectionBoxes_Precision/mAP (medium) = 0.54146665, DetectionBoxes_Precision/mAP (small) = 0.50425744, DetectionBoxes_Precision/mAP@.50IOU = 0.9633074, DetectionBoxes_Precision/mAP@.75IOU = 0.6158065, DetectionBoxes_Recall/AR@1 = 0.6142857, DetectionBoxes_Recall/AR@10 = 0.64047617, DetectionBoxes_Recall/AR@100 = 0.64047617, DetectionBoxes_Recall/AR@100 (large) = 0.6875, DetectionBoxes_Recall/AR@100 (medium) = 0.63684213, DetectionBoxes_Recall/AR@100 (small) = 0.54285717, Loss/classification_loss = 1.8925078, Loss/localization_loss = 0.7839102, Loss/regularization_loss = 0.27316922, Loss/total_loss = 2.9495873, global_step = 14298, learning_rate = 0.004, loss = 2.9495873\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14298: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-14298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01978\n",
      "INFO:tensorflow:loss = 0.9002887, step = 14300 (98.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56991\n",
      "INFO:tensorflow:loss = 0.91000843, step = 14400 (63.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5707\n",
      "INFO:tensorflow:loss = 0.81264305, step = 14500 (63.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57124\n",
      "INFO:tensorflow:loss = 0.81513053, step = 14600 (63.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 0.8372662, step = 14700 (63.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56152\n",
      "INFO:tensorflow:loss = 0.87939274, step = 14800 (63.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56211\n",
      "INFO:tensorflow:loss = 0.76295626, step = 14900 (64.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55836\n",
      "INFO:tensorflow:loss = 1.021116, step = 15000 (64.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55446\n",
      "INFO:tensorflow:loss = 1.2083338, step = 15100 (64.375 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15184 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24706\n",
      "INFO:tensorflow:loss = 0.96930647, step = 15200 (80.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56814\n",
      "INFO:tensorflow:loss = 0.6780444, step = 15300 (63.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57709\n",
      "INFO:tensorflow:loss = 1.1074436, step = 15400 (63.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55693\n",
      "INFO:tensorflow:loss = 1.1565608, step = 15500 (64.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56887\n",
      "INFO:tensorflow:loss = 1.030092, step = 15600 (63.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56774\n",
      "INFO:tensorflow:loss = 0.68787956, step = 15700 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.991865\n",
      "INFO:tensorflow:loss = 1.0062313, step = 15800 (100.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15870 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:00:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-15870\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.738\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.643\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:00:21\n",
      "INFO:tensorflow:Saving dict for global step 15870: DetectionBoxes_Precision/mAP = 0.6064884, DetectionBoxes_Precision/mAP (large) = 0.69591576, DetectionBoxes_Precision/mAP (medium) = 0.5733023, DetectionBoxes_Precision/mAP (small) = 0.59240925, DetectionBoxes_Precision/mAP@.50IOU = 0.9579542, DetectionBoxes_Precision/mAP@.75IOU = 0.7384766, DetectionBoxes_Recall/AR@1 = 0.64761907, DetectionBoxes_Recall/AR@10 = 0.68095237, DetectionBoxes_Recall/AR@100 = 0.68095237, DetectionBoxes_Recall/AR@100 (large) = 0.73125, DetectionBoxes_Recall/AR@100 (medium) = 0.6526316, DetectionBoxes_Recall/AR@100 (small) = 0.64285713, Loss/classification_loss = 1.7238725, Loss/localization_loss = 0.5887839, Loss/regularization_loss = 0.27324325, Loss/total_loss = 2.5858994, global_step = 15870, learning_rate = 0.004, loss = 2.5858994\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15870: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-15870\n",
      "INFO:tensorflow:global_step/sec: 0.314359\n",
      "INFO:tensorflow:loss = 0.883607, step = 15900 (318.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.317727\n",
      "INFO:tensorflow:loss = 0.6040118, step = 16000 (314.800 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16064 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:10:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16064\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.975\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.681\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:10:22\n",
      "INFO:tensorflow:Saving dict for global step 16064: DetectionBoxes_Precision/mAP = 0.6219332, DetectionBoxes_Precision/mAP (large) = 0.70883775, DetectionBoxes_Precision/mAP (medium) = 0.5945535, DetectionBoxes_Precision/mAP (small) = 0.53943896, DetectionBoxes_Precision/mAP@.50IOU = 0.97462386, DetectionBoxes_Precision/mAP@.75IOU = 0.7289741, DetectionBoxes_Recall/AR@1 = 0.68095237, DetectionBoxes_Recall/AR@10 = 0.6857143, DetectionBoxes_Recall/AR@100 = 0.6857143, DetectionBoxes_Recall/AR@100 (large) = 0.75, DetectionBoxes_Recall/AR@100 (medium) = 0.6631579, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 1.5667795, Loss/localization_loss = 0.5852163, Loss/regularization_loss = 0.27324012, Loss/total_loss = 2.4252362, global_step = 16064, learning_rate = 0.004, loss = 2.4252362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16064: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16064\n",
      "INFO:tensorflow:global_step/sec: 0.344691\n",
      "INFO:tensorflow:loss = 1.2935743, step = 16100 (290.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.378348\n",
      "INFO:tensorflow:loss = 0.8552778, step = 16200 (264.355 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16272 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:20:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16272\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:20:35\n",
      "INFO:tensorflow:Saving dict for global step 16272: DetectionBoxes_Precision/mAP = 0.6255399, DetectionBoxes_Precision/mAP (large) = 0.6928599, DetectionBoxes_Precision/mAP (medium) = 0.5952943, DetectionBoxes_Precision/mAP (small) = 0.6089109, DetectionBoxes_Precision/mAP@.50IOU = 0.97706807, DetectionBoxes_Precision/mAP@.75IOU = 0.78562766, DetectionBoxes_Recall/AR@1 = 0.6857143, DetectionBoxes_Recall/AR@10 = 0.6880952, DetectionBoxes_Recall/AR@100 = 0.6880952, DetectionBoxes_Recall/AR@100 (large) = 0.725, DetectionBoxes_Recall/AR@100 (medium) = 0.66842103, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.5801471, Loss/localization_loss = 0.5756079, Loss/regularization_loss = 0.27324077, Loss/total_loss = 2.4289956, global_step = 16272, learning_rate = 0.004, loss = 2.4289956\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16272: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16272\n",
      "INFO:tensorflow:global_step/sec: 0.295482\n",
      "INFO:tensorflow:loss = 0.8404789, step = 16300 (338.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.376848\n",
      "INFO:tensorflow:loss = 0.8106563, step = 16400 (265.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16480 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.36582\n",
      "INFO:tensorflow:loss = 0.6431481, step = 16500 (273.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.399239\n",
      "INFO:tensorflow:loss = 0.7752738, step = 16600 (250.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666021\n",
      "INFO:tensorflow:loss = 0.93368864, step = 16700 (150.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57085\n",
      "INFO:tensorflow:loss = 1.1761229, step = 16800 (63.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16892 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T14:40:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16892\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.792\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.613\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-14:40:25\n",
      "INFO:tensorflow:Saving dict for global step 16892: DetectionBoxes_Precision/mAP = 0.642096, DetectionBoxes_Precision/mAP (large) = 0.7137838, DetectionBoxes_Precision/mAP (medium) = 0.60927624, DetectionBoxes_Precision/mAP (small) = 0.6128713, DetectionBoxes_Precision/mAP@.50IOU = 0.9863113, DetectionBoxes_Precision/mAP@.75IOU = 0.79225093, DetectionBoxes_Recall/AR@1 = 0.6952381, DetectionBoxes_Recall/AR@10 = 0.6952381, DetectionBoxes_Recall/AR@100 = 0.6952381, DetectionBoxes_Recall/AR@100 (large) = 0.74375, DetectionBoxes_Recall/AR@100 (medium) = 0.66842103, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.5993516, Loss/localization_loss = 0.5835063, Loss/regularization_loss = 0.27324685, Loss/total_loss = 2.456105, global_step = 16892, learning_rate = 0.004, loss = 2.456105\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16892: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-16892\n",
      "INFO:tensorflow:global_step/sec: 0.975222\n",
      "INFO:tensorflow:loss = 0.9713135, step = 16900 (102.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56067\n",
      "INFO:tensorflow:loss = 0.6992128, step = 17000 (64.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56552\n",
      "INFO:tensorflow:loss = 1.1359767, step = 17100 (63.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57706\n",
      "INFO:tensorflow:loss = 0.9338313, step = 17200 (63.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55381\n",
      "INFO:tensorflow:loss = 0.9387554, step = 17300 (64.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57065\n",
      "INFO:tensorflow:loss = 0.8930064, step = 17400 (63.631 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.57592\n",
      "INFO:tensorflow:loss = 0.9464767, step = 17500 (63.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54444\n",
      "INFO:tensorflow:loss = 1.0903716, step = 17600 (64.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54579\n",
      "INFO:tensorflow:loss = 1.1474949, step = 17700 (64.726 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17769 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24533\n",
      "INFO:tensorflow:loss = 0.78269476, step = 17800 (80.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55907\n",
      "INFO:tensorflow:loss = 0.91491616, step = 17900 (64.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5725\n",
      "INFO:tensorflow:loss = 0.88213885, step = 18000 (63.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55741\n",
      "INFO:tensorflow:loss = 1.0519183, step = 18100 (64.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56375\n",
      "INFO:tensorflow:loss = 0.9124009, step = 18200 (63.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56806\n",
      "INFO:tensorflow:loss = 1.1280371, step = 18300 (63.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51692\n",
      "INFO:tensorflow:loss = 0.9728357, step = 18400 (65.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55154\n",
      "INFO:tensorflow:loss = 0.80196345, step = 18500 (64.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56964\n",
      "INFO:tensorflow:loss = 0.7255701, step = 18600 (63.660 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18679 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:00:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-18679\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:00:21\n",
      "INFO:tensorflow:Saving dict for global step 18679: DetectionBoxes_Precision/mAP = 0.6869603, DetectionBoxes_Precision/mAP (large) = 0.7441254, DetectionBoxes_Precision/mAP (medium) = 0.66416097, DetectionBoxes_Precision/mAP (small) = 0.64908063, DetectionBoxes_Precision/mAP@.50IOU = 0.9969997, DetectionBoxes_Precision/mAP@.75IOU = 0.9078267, DetectionBoxes_Recall/AR@1 = 0.73333335, DetectionBoxes_Recall/AR@10 = 0.73333335, DetectionBoxes_Recall/AR@100 = 0.73333335, DetectionBoxes_Recall/AR@100 (large) = 0.76875, DetectionBoxes_Recall/AR@100 (medium) = 0.7157895, DetectionBoxes_Recall/AR@100 (small) = 0.7, Loss/classification_loss = 1.4347214, Loss/localization_loss = 0.39434963, Loss/regularization_loss = 0.27321532, Loss/total_loss = 2.102286, global_step = 18679, learning_rate = 0.004, loss = 2.102286\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18679: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-18679\n",
      "INFO:tensorflow:global_step/sec: 1.02138\n",
      "INFO:tensorflow:loss = 0.6798589, step = 18700 (97.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56757\n",
      "INFO:tensorflow:loss = 1.0436704, step = 18800 (63.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56289\n",
      "INFO:tensorflow:loss = 0.7282069, step = 18900 (64.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5723\n",
      "INFO:tensorflow:loss = 1.0322585, step = 19000 (63.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58464\n",
      "INFO:tensorflow:loss = 1.00373, step = 19100 (63.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57426\n",
      "INFO:tensorflow:loss = 0.844666, step = 19200 (63.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.543\n",
      "INFO:tensorflow:loss = 0.87813723, step = 19300 (64.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53936\n",
      "INFO:tensorflow:loss = 1.1613348, step = 19400 (64.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54708\n",
      "INFO:tensorflow:loss = 0.8205923, step = 19500 (64.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19563 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.24824\n",
      "INFO:tensorflow:loss = 0.7625221, step = 19600 (80.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5686\n",
      "INFO:tensorflow:loss = 0.7731677, step = 19700 (63.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56267\n",
      "INFO:tensorflow:loss = 0.8618427, step = 19800 (63.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56544\n",
      "INFO:tensorflow:loss = 0.8546407, step = 19900 (63.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56828\n",
      "INFO:tensorflow:loss = 1.3111031, step = 20000 (63.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56309\n",
      "INFO:tensorflow:loss = 0.8288491, step = 20100 (64.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5616\n",
      "INFO:tensorflow:loss = 0.87856007, step = 20200 (63.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55111\n",
      "INFO:tensorflow:loss = 0.8171362, step = 20300 (64.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56045\n",
      "INFO:tensorflow:loss = 0.79535747, step = 20400 (64.043 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20476 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:20:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-20476\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.699\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.882\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.619\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:20:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 20476: DetectionBoxes_Precision/mAP = 0.69901836, DetectionBoxes_Precision/mAP (large) = 0.7628584, DetectionBoxes_Precision/mAP (medium) = 0.67839986, DetectionBoxes_Precision/mAP (small) = 0.61915135, DetectionBoxes_Precision/mAP@.50IOU = 0.9615337, DetectionBoxes_Precision/mAP@.75IOU = 0.8822593, DetectionBoxes_Recall/AR@1 = 0.7404762, DetectionBoxes_Recall/AR@10 = 0.7404762, DetectionBoxes_Recall/AR@100 = 0.7404762, DetectionBoxes_Recall/AR@100 (large) = 0.79375, DetectionBoxes_Recall/AR@100 (medium) = 0.7157895, DetectionBoxes_Recall/AR@100 (small) = 0.6857143, Loss/classification_loss = 1.3517916, Loss/localization_loss = 0.39165568, Loss/regularization_loss = 0.2731545, Loss/total_loss = 2.016602, global_step = 20476, learning_rate = 0.004, loss = 2.016602\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20476: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-20476\n",
      "INFO:tensorflow:global_step/sec: 1.02505\n",
      "INFO:tensorflow:loss = 0.799726, step = 20500 (97.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57447\n",
      "INFO:tensorflow:loss = 0.72079635, step = 20600 (63.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57369\n",
      "INFO:tensorflow:loss = 0.9073359, step = 20700 (63.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56187\n",
      "INFO:tensorflow:loss = 1.5515928, step = 20800 (63.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56796\n",
      "INFO:tensorflow:loss = 0.87144166, step = 20900 (63.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57764\n",
      "INFO:tensorflow:loss = 0.9749163, step = 21000 (63.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57238\n",
      "INFO:tensorflow:loss = 1.0355136, step = 21100 (63.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57565\n",
      "INFO:tensorflow:loss = 0.6866902, step = 21200 (63.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58391\n",
      "INFO:tensorflow:loss = 0.69730806, step = 21300 (63.175 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21368 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:30:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-21368\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.959\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.861\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.615\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.726\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:30:21\n",
      "INFO:tensorflow:Saving dict for global step 21368: DetectionBoxes_Precision/mAP = 0.7073704, DetectionBoxes_Precision/mAP (large) = 0.77702326, DetectionBoxes_Precision/mAP (medium) = 0.6940058, DetectionBoxes_Precision/mAP (small) = 0.6152145, DetectionBoxes_Precision/mAP@.50IOU = 0.959461, DetectionBoxes_Precision/mAP@.75IOU = 0.86071026, DetectionBoxes_Recall/AR@1 = 0.74761903, DetectionBoxes_Recall/AR@10 = 0.74761903, DetectionBoxes_Recall/AR@100 = 0.74761903, DetectionBoxes_Recall/AR@100 (large) = 0.80625, DetectionBoxes_Recall/AR@100 (medium) = 0.7263158, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.2012084, Loss/localization_loss = 0.36212203, Loss/regularization_loss = 0.2731154, Loss/total_loss = 1.8364462, global_step = 21368, learning_rate = 0.004, loss = 1.8364462\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21368: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-21368\n",
      "INFO:tensorflow:global_step/sec: 1.03669\n",
      "INFO:tensorflow:loss = 0.68299955, step = 21400 (96.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58788\n",
      "INFO:tensorflow:loss = 0.7283222, step = 21500 (63.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58431\n",
      "INFO:tensorflow:loss = 0.84869087, step = 21600 (63.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59119\n",
      "INFO:tensorflow:loss = 0.8874027, step = 21700 (62.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5901\n",
      "INFO:tensorflow:loss = 0.87586397, step = 21800 (62.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59157\n",
      "INFO:tensorflow:loss = 0.8719399, step = 21900 (62.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58791\n",
      "INFO:tensorflow:loss = 1.2967674, step = 22000 (62.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5898\n",
      "INFO:tensorflow:loss = 1.2427669, step = 22100 (62.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58265\n",
      "INFO:tensorflow:loss = 0.65139127, step = 22200 (63.143 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22269 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.26494\n",
      "INFO:tensorflow:loss = 0.73308, step = 22300 (79.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58738\n",
      "INFO:tensorflow:loss = 0.8266683, step = 22400 (62.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59038\n",
      "INFO:tensorflow:loss = 0.73603874, step = 22500 (62.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59051\n",
      "INFO:tensorflow:loss = 1.4147407, step = 22600 (62.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58993\n",
      "INFO:tensorflow:loss = 1.0635802, step = 22700 (62.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58466\n",
      "INFO:tensorflow:loss = 0.8350389, step = 22800 (63.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59253\n",
      "INFO:tensorflow:loss = 0.77145517, step = 22900 (62.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58579\n",
      "INFO:tensorflow:loss = 0.86105484, step = 23000 (63.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58931\n",
      "INFO:tensorflow:loss = 0.81072986, step = 23100 (62.949 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23197 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T15:50:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-23197\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.608\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.815\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.726\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-15:50:22\n",
      "INFO:tensorflow:Saving dict for global step 23197: DetectionBoxes_Precision/mAP = 0.72519535, DetectionBoxes_Precision/mAP (large) = 0.81514525, DetectionBoxes_Precision/mAP (medium) = 0.6975975, DetectionBoxes_Precision/mAP (small) = 0.6080622, DetectionBoxes_Precision/mAP@.50IOU = 0.9641468, DetectionBoxes_Precision/mAP@.75IOU = 0.8812984, DetectionBoxes_Recall/AR@1 = 0.7619048, DetectionBoxes_Recall/AR@10 = 0.7619048, DetectionBoxes_Recall/AR@100 = 0.7619048, DetectionBoxes_Recall/AR@100 (large) = 0.85, DetectionBoxes_Recall/AR@100 (medium) = 0.7263158, DetectionBoxes_Recall/AR@100 (small) = 0.6571429, Loss/classification_loss = 1.717074, Loss/localization_loss = 0.3734939, Loss/regularization_loss = 0.2729295, Loss/total_loss = 2.3634975, global_step = 23197, learning_rate = 0.004, loss = 2.3634975\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 23197: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-23197\n",
      "INFO:tensorflow:global_step/sec: 1.04114\n",
      "INFO:tensorflow:loss = 0.6659199, step = 23200 (96.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57878\n",
      "INFO:tensorflow:loss = 1.8969074, step = 23300 (63.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57188\n",
      "INFO:tensorflow:loss = 0.7378943, step = 23400 (63.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54285\n",
      "INFO:tensorflow:loss = 0.91421247, step = 23500 (64.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56755\n",
      "INFO:tensorflow:loss = 1.0277197, step = 23600 (63.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58496\n",
      "INFO:tensorflow:loss = 0.64031607, step = 23700 (63.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58682\n",
      "INFO:tensorflow:loss = 0.71459186, step = 23800 (62.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59023\n",
      "INFO:tensorflow:loss = 1.0704232, step = 23900 (62.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58088\n",
      "INFO:tensorflow:loss = 1.1263257, step = 24000 (63.210 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24091 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:00:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24091\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.648\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.753\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:00:22\n",
      "INFO:tensorflow:Saving dict for global step 24091: DetectionBoxes_Precision/mAP = 0.7231673, DetectionBoxes_Precision/mAP (large) = 0.758775, DetectionBoxes_Precision/mAP (medium) = 0.7174343, DetectionBoxes_Precision/mAP (small) = 0.64848655, DetectionBoxes_Precision/mAP@.50IOU = 0.95492333, DetectionBoxes_Precision/mAP@.75IOU = 0.9401619, DetectionBoxes_Recall/AR@1 = 0.75476193, DetectionBoxes_Recall/AR@10 = 0.75476193, DetectionBoxes_Recall/AR@100 = 0.75476193, DetectionBoxes_Recall/AR@100 (large) = 0.79375, DetectionBoxes_Recall/AR@100 (medium) = 0.7526316, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.5016155, Loss/localization_loss = 0.36365736, Loss/regularization_loss = 0.27286178, Loss/total_loss = 2.1381345, global_step = 24091, learning_rate = 0.004, loss = 2.1381345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24091: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24091\n",
      "INFO:tensorflow:global_step/sec: 1.03873\n",
      "INFO:tensorflow:loss = 0.9755063, step = 24100 (96.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59309\n",
      "INFO:tensorflow:loss = 0.7597003, step = 24200 (62.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59086\n",
      "INFO:tensorflow:loss = 0.61712456, step = 24300 (62.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58471\n",
      "INFO:tensorflow:loss = 0.7111548, step = 24400 (63.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58846\n",
      "INFO:tensorflow:loss = 0.7269006, step = 24500 (62.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58748\n",
      "INFO:tensorflow:loss = 1.5439472, step = 24600 (62.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59137\n",
      "INFO:tensorflow:loss = 0.78630674, step = 24700 (62.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56057\n",
      "INFO:tensorflow:loss = 0.8128227, step = 24800 (64.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57891\n",
      "INFO:tensorflow:loss = 1.27707, step = 24900 (63.364 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24989 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:10:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24989\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.864\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.590\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.748\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.784\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:10:23\n",
      "INFO:tensorflow:Saving dict for global step 24989: DetectionBoxes_Precision/mAP = 0.7446748, DetectionBoxes_Precision/mAP (large) = 0.8131541, DetectionBoxes_Precision/mAP (medium) = 0.7482075, DetectionBoxes_Precision/mAP (small) = 0.59019333, DetectionBoxes_Precision/mAP@.50IOU = 0.95519453, DetectionBoxes_Precision/mAP@.75IOU = 0.8643052, DetectionBoxes_Recall/AR@1 = 0.7785714, DetectionBoxes_Recall/AR@10 = 0.7785714, DetectionBoxes_Recall/AR@100 = 0.7785714, DetectionBoxes_Recall/AR@100 (large) = 0.8375, DetectionBoxes_Recall/AR@100 (medium) = 0.7842105, DetectionBoxes_Recall/AR@100 (small) = 0.62857145, Loss/classification_loss = 1.6088853, Loss/localization_loss = 0.37177408, Loss/regularization_loss = 0.27278414, Loss/total_loss = 2.2534435, global_step = 24989, learning_rate = 0.004, loss = 2.2534435\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24989: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-24989\n",
      "INFO:tensorflow:global_step/sec: 1.02692\n",
      "INFO:tensorflow:loss = 1.0248054, step = 25000 (97.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57943\n",
      "INFO:tensorflow:loss = 0.89895195, step = 25100 (63.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57042\n",
      "INFO:tensorflow:loss = 0.83390296, step = 25200 (63.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57067\n",
      "INFO:tensorflow:loss = 0.8476748, step = 25300 (63.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57555\n",
      "INFO:tensorflow:loss = 0.74731374, step = 25400 (63.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54875\n",
      "INFO:tensorflow:loss = 0.7604755, step = 25500 (64.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55562\n",
      "INFO:tensorflow:loss = 1.02278, step = 25600 (64.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56099\n",
      "INFO:tensorflow:loss = 0.77244276, step = 25700 (64.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5395\n",
      "INFO:tensorflow:loss = 0.97929126, step = 25800 (64.910 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25875 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:20:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-25875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.904\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.623\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.752\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.774\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:20:24\n",
      "INFO:tensorflow:Saving dict for global step 25875: DetectionBoxes_Precision/mAP = 0.7394448, DetectionBoxes_Precision/mAP (large) = 0.7797261, DetectionBoxes_Precision/mAP (medium) = 0.7521775, DetectionBoxes_Precision/mAP (small) = 0.6232815, DetectionBoxes_Precision/mAP@.50IOU = 0.9622499, DetectionBoxes_Precision/mAP@.75IOU = 0.90416056, DetectionBoxes_Recall/AR@1 = 0.77380955, DetectionBoxes_Recall/AR@10 = 0.77380955, DetectionBoxes_Recall/AR@100 = 0.77380955, DetectionBoxes_Recall/AR@100 (large) = 0.81875, DetectionBoxes_Recall/AR@100 (medium) = 0.7736842, DetectionBoxes_Recall/AR@100 (small) = 0.67142856, Loss/classification_loss = 1.4879309, Loss/localization_loss = 0.33437285, Loss/regularization_loss = 0.2726813, Loss/total_loss = 2.0949852, global_step = 25875, learning_rate = 0.004, loss = 2.0949852\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25875: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-25875\n",
      "INFO:tensorflow:global_step/sec: 1.02232\n",
      "INFO:tensorflow:loss = 0.6737645, step = 25900 (97.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57384\n",
      "INFO:tensorflow:loss = 0.825817, step = 26000 (63.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57141\n",
      "INFO:tensorflow:loss = 1.3746493, step = 26100 (63.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56939\n",
      "INFO:tensorflow:loss = 1.046996, step = 26200 (63.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56651\n",
      "INFO:tensorflow:loss = 0.654708, step = 26300 (63.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56868\n",
      "INFO:tensorflow:loss = 0.5932985, step = 26400 (63.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57522\n",
      "INFO:tensorflow:loss = 0.88954806, step = 26500 (63.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56382\n",
      "INFO:tensorflow:loss = 0.65953696, step = 26600 (63.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56026\n",
      "INFO:tensorflow:loss = 0.9659239, step = 26700 (64.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26763 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.2361\n",
      "INFO:tensorflow:loss = 0.78418833, step = 26800 (80.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56845\n",
      "INFO:tensorflow:loss = 0.7976807, step = 26900 (63.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5689\n",
      "INFO:tensorflow:loss = 0.8853276, step = 27000 (63.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57166\n",
      "INFO:tensorflow:loss = 0.6431623, step = 27100 (63.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5687\n",
      "INFO:tensorflow:loss = 0.8535866, step = 27200 (63.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56774\n",
      "INFO:tensorflow:loss = 1.4721314, step = 27300 (63.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54789\n",
      "INFO:tensorflow:loss = 0.86394846, step = 27400 (64.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.816526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8492899, step = 27500 (122.550 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27584 into ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-18T16:40:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-27584\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.884\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.742\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.760\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.763\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-18-16:40:30\n",
      "INFO:tensorflow:Saving dict for global step 27584: DetectionBoxes_Precision/mAP = 0.72967446, DetectionBoxes_Precision/mAP (large) = 0.79412615, DetectionBoxes_Precision/mAP (medium) = 0.7418968, DetectionBoxes_Precision/mAP (small) = 0.55263555, DetectionBoxes_Precision/mAP@.50IOU = 0.96707344, DetectionBoxes_Precision/mAP@.75IOU = 0.8836256, DetectionBoxes_Recall/AR@1 = 0.7595238, DetectionBoxes_Recall/AR@10 = 0.7595238, DetectionBoxes_Recall/AR@100 = 0.7595238, DetectionBoxes_Recall/AR@100 (large) = 0.825, DetectionBoxes_Recall/AR@100 (medium) = 0.7631579, DetectionBoxes_Recall/AR@100 (small) = 0.6, Loss/classification_loss = 1.5778269, Loss/localization_loss = 0.3987388, Loss/regularization_loss = 0.2724136, Loss/total_loss = 2.2489796, global_step = 27584, learning_rate = 0.004, loss = 2.2489796\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 27584: ../../output/plate_detection/checkpoints/ssdlite_mobilenet_v2_coco_2018_05_09\\model.ckpt-27584\n",
      "INFO:tensorflow:global_step/sec: 0.969073\n",
      "INFO:tensorflow:loss = 0.97856426, step = 27600 (103.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57075\n",
      "INFO:tensorflow:loss = 0.85057807, step = 27700 (63.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56568\n",
      "INFO:tensorflow:loss = 0.85169435, step = 27800 (63.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55214\n",
      "INFO:tensorflow:loss = 0.8647555, step = 27900 (64.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55465\n",
      "INFO:tensorflow:loss = 1.1403918, step = 28000 (64.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56563\n",
      "INFO:tensorflow:loss = 0.74429053, step = 28100 (63.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56855\n",
      "INFO:tensorflow:loss = 0.7892519, step = 28200 (63.709 sec)\n"
     ]
    }
   ],
   "source": [
    "%run model_main.py --pipeline_config_path={PIPELINE_CONFING_FILEPATH} --model_dir={CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Finetuned Model\n",
    "If the training is finished, the model must be exported so that it can be used.\n",
    "\n",
    "Set CHECKPOINT_NO = 'XXX' where XXX is the number of the last checkpoint file in CHECKPOINTS_DIR, before you start the export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Inputs..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0318 06:56:41.540622 19104 deprecation_wrapper.py:119] From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0318 06:56:41.544592 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0318 06:56:41.544592 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0318 06:56:41.566620 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\meta_architectures\\ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0318 06:56:41.584622 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\meta_architectures\\ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\meta_architectures\\ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0318 06:56:41.584622 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\meta_architectures\\ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.633620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0E1780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0E1780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.654621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0E1780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0E1780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB159BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB159BE0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.680620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB159BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB159BE0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18F780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18F780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.724621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18F780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18F780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.743621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.788620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0E1A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/3.20m params)\n",
      "  BoxPredictor_0 (--/93.33k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/62.22k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (3x3x576x12, 62.21k/62.21k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/31.11k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (3x3x576x6, 31.10k/31.10k params)\n",
      "  BoxPredictor_1 (--/138.25k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/92.17k params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.809620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB269C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB269C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.836621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB269C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB269C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB1FDCC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB1FDCC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.881620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB1FDCC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB1FDCC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.900620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7EF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7EF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.946620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7EF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7EF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.966620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB364FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB364FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:41.993620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB364FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB364FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.040620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB2D7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.060622 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB0F2470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB403C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB403C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.106620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB403C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB403C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAB38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.125620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAB38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB403FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB403FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.151591 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB403FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB403FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB364978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB364978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.196626 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB364978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB364978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.217622 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.263591 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB13E2B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB13E2B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.329590 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB13E2B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB13E2B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.355620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4B9358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52CC50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52CC50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.400620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52CC50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52CC50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB2BFE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB2BFE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.420621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB2BFE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB2BFE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.466620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB622B70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB622B70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.485620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB622B70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB622B70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.512620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.557621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB5F4320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAC18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.576620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAC18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6EDEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6EDEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.622621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6EDEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6EDEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAEF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAEF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.642621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAEF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB3EAEF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB747FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB747FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.668621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB747FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB747FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6B5CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6B5CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.713591 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6B5CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB6B5CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4E69E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4E69E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.734630 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4E69E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB4E69E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.784620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB4E6FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB52C2B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB52C2B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.806620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB52C2B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB52C2B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.834591 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB707358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB707358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.881621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB707358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB707358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.901622 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB594E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52C278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52C278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.947620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52C278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB52C278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.967620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8FBDD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8FBDD8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:42.993620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8FBDD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8FBDD8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB85BE10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB85BE10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.038620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB85BE10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB85BE10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9CC518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9CC518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0318 06:56:43.058623 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9CC518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9CC518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB9CC470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB9CC470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.104621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB9CC470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB9CC470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7075C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7075C0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.124623 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7075C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7075C0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA235F8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA235F8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.151625 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA235F8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA235F8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA395F8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA395F8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.196620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA395F8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA395F8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.216620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB7B4E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBAF49E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBAF49E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.262624 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBAF49E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBAF49E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB82EC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB82EC88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.282621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB82EC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB82EC88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB7B9B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB7B9B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.309621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB7B9B0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB7B9B0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA23E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA23E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.355620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA23E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBA23E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.375620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBBBADA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBBBADA0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.420620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBBBADA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBBBADA0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.440623 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB8E2668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC42518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC42518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.466621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC42518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC42518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBB7B588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBB7B588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.510626 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBB7B588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBB7B588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9D9FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9D9FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.530620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9D9FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BB9D9FD0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBCB42E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBCB42E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.576620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBCB42E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBCB42E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA23C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA23C18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.596615 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA23C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBA23C18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.625593 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBC428D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBC428D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.672621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBC428D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBC428D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBABA8D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBABA8D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.693628 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBABA8D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBABA8D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDD32E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDD32E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.784620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDD32E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDD32E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB0D3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB0D3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.805615 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB0D3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBB0D3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE39E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE39E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.837631 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE39E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE39E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDFEF60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDFEF60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.888592 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDFEF60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDFEF60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBE7D278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBE7D278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.909623 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBE7D278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBE7D278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDE3EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDE3EB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.956621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDE3EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBDE3EB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC35358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC35358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:43.976626 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC35358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBC35358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBF1A1D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBF1A1D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.003621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBF1A1D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBF1A1D0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.047620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.067621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBCB4CF8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBFF4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBFF4860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.112620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBFF4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBFF4860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBD24C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBD24C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.132621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBD24C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBD24C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBFBF0F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBFBF0F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.158620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBFBF0F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBFBF0F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBF1A278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBF1A278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.203622 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBF1A278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBF1A278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3DD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3DD8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.223620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3DD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3DD8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC0BBD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC0BBD68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.269620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC0BBD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC0BBD68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3F98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3F98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.288625 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3F98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDE3F98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC17F668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC17F668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.315622 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC17F668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC17F668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC081D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC081D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.361620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC081D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC081D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDB7BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDB7BE0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.381620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDB7BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBDB7BE0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18B9E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18B9E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.425620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18B9E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB18B9E8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC160C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC160C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.448621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC160C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC160C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0CFA20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0CFA20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.502620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0CFA20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BB0CFA20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBEA9E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBEA9E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.522621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBEA9E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BBEA9E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC27EE80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC27EE80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.548620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC27EE80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC27EE80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC18D390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC18D390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.592624 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC18D390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC18D390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC32FEF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC32FEF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.613620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC32FEF0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC32FEF0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.658622 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BBEA9E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC314A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC314A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.678620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC314A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC314A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC3B1978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC3B1978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.705620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC3B1978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC3B1978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.750620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC42F4E0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC42F4E0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.770623 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC42F4E0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC42F4E0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC314128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC314128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.815620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC314128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC314128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC408CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC408CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.835617 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC408CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC408CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC4A4BA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC4A4BA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.862620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC4A4BA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC4A4BA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC4A4908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC4A4908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.906620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC4A4908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC4A4908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC23C978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC23C978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.926621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC23C978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC23C978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1B70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1B70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.971622 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1B70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC3B1B70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC37C198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC37C198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:44.991620 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC37C198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BC37C198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD561E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD561E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.018621 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD561E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD561E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BD561E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BD561E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.063620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BD561E80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BD561E80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD5D0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD5D0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.083622 19104 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD5D0390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x00000270BD5D0390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0318 06:56:45.528620 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\predictors\\convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0318 06:56:45.536620 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\predictors\\convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:45.536620 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.582620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.633620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:45.638627 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.683620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.734620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB25828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:45.739618 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB2E748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB2E748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.785620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB2E748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB2E748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC511240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC511240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.836620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC511240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BC511240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:45.841620 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1C4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1C4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.887620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1C4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1C4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1CB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1CB38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.938620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1CB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDC1CB38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:45.943621 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:45.989621 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:46.040620 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB5BB00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0318 06:56:46.044620 19104 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDCB5C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDCB5C18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:46.090626 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDCB5C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDCB5C18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB74048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB74048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "W0318 06:56:46.141628 19104 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB74048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000270BDB74048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\post_processing.py:581: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0318 06:56:46.298621 19104 deprecation.py:323] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\core\\post_processing.py:581: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0318 06:56:46.530620 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0318 06:56:46.530620 19104 deprecation.py:323] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W0318 06:56:46.532621 19104 deprecation.py:323] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W0318 06:56:46.533620 19104 deprecation.py:323] From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "155 ops no flops stats due to incomplete shapes.\n",
      "155 ops no flops stats due to incomplete shapes.\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0318 06:56:47.469620 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "2020-03-18 06:56:48.232513: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\n",
      "2020-03-18 06:56:48.258838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.83\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-18 06:56:48.259091: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-03-18 06:56:48.259679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-03-18 06:56:48.260481: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2020-03-18 06:56:48.265027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.83\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-18 06:56:48.265269: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-03-18 06:56:48.265802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-03-18 06:56:48.771475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 06:56:48.771668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-03-18 06:56:48.771776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-03-18 06:56:48.772426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6314 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0318 06:56:48.776619 19104 deprecation.py:323] From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt-30000\n",
      "I0318 06:56:48.779593 19104 saver.py:1280] Restoring parameters from ../../output/plate_detection/checkpoints/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt-30000\n",
      "2020-03-18 06:57:17.093247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.83\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-18 06:57:17.095084: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-03-18 06:57:17.095664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-03-18 06:57:17.097703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 06:57:17.097892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-03-18 06:57:17.098008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-03-18 06:57:17.101129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6314 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from ../../output/plate_detection/checkpoints/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt-30000\n",
      "I0318 06:57:17.106338 19104 saver.py:1280] Restoring parameters from ../../output/plate_detection/checkpoints/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt-30000\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0318 06:57:17.606335 19104 deprecation.py:323] From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0318 06:57:17.607335 19104 deprecation.py:323] From C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 344 variables.\n",
      "I0318 06:57:18.206361 19104 graph_util_impl.py:311] Froze 344 variables.\n",
      "INFO:tensorflow:Converted 344 variables to const ops.\n",
      "I0318 06:57:18.283336 19104 graph_util_impl.py:364] Converted 344 variables to const ops.\n",
      "2020-03-18 06:57:18.561217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.83\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-18 06:57:18.561553: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-03-18 06:57:18.563014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-03-18 06:57:18.563246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-18 06:57:18.563431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-03-18 06:57:18.563687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-03-18 06:57:18.566222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6314 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "W0318 06:57:18.880902 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0318 06:57:18.881873 19104 deprecation.py:323] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "W0318 06:57:18.881873 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "W0318 06:57:18.881873 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "W0318 06:57:18.881873 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "W0318 06:57:18.881873 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0318 06:57:18.881873 19104 builder_impl.py:636] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0318 06:57:18.881873 19104 builder_impl.py:456] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../../output/plate_detection/fine_tuned_models/ssd_mobilenet_v2_coco_2018_03_29\\saved_model\\saved_model.pb\n",
      "I0318 06:57:19.244911 19104 builder_impl.py:421] SavedModel written to: ../../output/plate_detection/fine_tuned_models/ssd_mobilenet_v2_coco_2018_03_29\\saved_model\\saved_model.pb\n",
      "WARNING:tensorflow:From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\utils\\config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0318 06:57:19.260941 19104 deprecation_wrapper.py:119] From D:\\development\\mlnd\\German_License_Plate_Recognition\\tf_object_detection\\object_detection\\utils\\config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:Writing pipeline config file to ../../output/plate_detection/fine_tuned_models/ssd_mobilenet_v2_coco_2018_03_29\\pipeline.config\n",
      "I0318 06:57:19.261912 19104 config_util.py:190] Writing pipeline config file to ../../output/plate_detection/fine_tuned_models/ssd_mobilenet_v2_coco_2018_03_29\\pipeline.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BoxPredictor_1/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (3x3x1280x8, 92.16k/92.16k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/46.08k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (4, 4/4 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (3x3x1280x4, 46.08k/46.08k params)\n",
      "  BoxPredictor_2 (--/55.31k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/36.87k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (3x3x512x8, 36.86k/36.86k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/18.44k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (4, 4/4 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (3x3x512x4, 18.43k/18.43k params)\n",
      "  BoxPredictor_3 (--/27.66k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/18.44k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (3x3x256x8, 18.43k/18.43k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/9.22k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (4, 4/4 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (3x3x256x4, 9.22k/9.22k params)\n",
      "  BoxPredictor_4 (--/27.66k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/18.44k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (3x3x256x8, 18.43k/18.43k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/9.22k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (4, 4/4 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (3x3x256x4, 9.22k/9.22k params)\n",
      "  BoxPredictor_5 (--/13.84k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/9.22k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (3x3x128x8, 9.22k/9.22k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/4.61k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (4, 4/4 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (3x3x128x4, 4.61k/4.61k params)\n",
      "  FeatureExtractor (--/2.84m params)\n",
      "    FeatureExtractor/MobilenetV2 (--/2.84m params)\n",
      "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
      "\n",
      "======================End of Report==========================\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/12.55k flops)\n",
      "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (400/400 flops)\n",
      "  MultipleGridAnchorGenerator/add_5 (400/400 flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (400/400 flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (400/400 flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (200/200 flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (100/100 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (100/100 flops)\n",
      "  MultipleGridAnchorGenerator/add_8 (100/100 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (100/100 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (50/50 flops)\n",
      "  MultipleGridAnchorGenerator/add_11 (36/36 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (36/36 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (36/36 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (36/36 flops)\n",
      "  MultipleGridAnchorGenerator/add (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (18/18 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/add_14 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (8/8 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_17 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/add (1/1 flops)\n",
      "  Preprocessor/map/while/add_1 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_NO = 30000\n",
    "\n",
    "!python export_inference_graph.py --pipeline_config_path={PIPELINE_CONFING_FILEPATH} --trained_checkpoint_prefix={CHECKPOINTS_DIR}/model.ckpt-{CHECKPOINT_NO} --output_directory={FINETUNED_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Traffic Light Detection\n",
    "\n",
    "Uses the fine tuned traffic light detection model FINETUNED_MODEL_DIR to detect traffic lights in images.\n",
    "\n",
    "#### Load the (frozen) finetuned model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading label map\n",
    "Loads the label map file PATH_TO_LABELS. This file contains a map that assigns category names to the class-indices:\n",
    "\n",
    "item { id: 1 name: 'Green' }\n",
    "\n",
    "item { id: 2 name: 'Yellow' }\n",
    "\n",
    "item { id: 3 name: 'Red' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 test images found in ../../data/plate_detection/test_images\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '../../data/plate_detection/test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = []\n",
    "for filename in glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg')):\n",
    "    TEST_IMAGE_PATHS.append(filename)\n",
    "    \n",
    "print ('{} test images found in {}'.format(len(TEST_IMAGE_PATHS), PATH_TO_TEST_IMAGES_DIR))\n",
    "\n",
    "plt.imshow(mpimg.imread(TEST_IMAGE_PATHS[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# number of samples to test; -1 <=> all\n",
    "NUM_SAMPLES = 2\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 12)\n",
    "\n",
    "if NUM_SAMPLES > 0:\n",
    "    test_images = np.random.choice(TEST_IMAGE_PATHS, size = NUM_SAMPLES, replace=False)\n",
    "else:\n",
    "    test_images = TEST_IMAGE_PATHS\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for image_path in test_images:\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=4)\n",
    "            plt.figure(figsize=IMAGE_SIZE)\n",
    "            plt.title(image_path)\n",
    "            plt.imshow(image_np)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "TOCO failed. See console for info.\n2020-03-18 06:58:35.038994: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.039329: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp\n2020-03-18 06:58:35.039530: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"NoOp\" device_type: \"GPU\"') for unknown op: NoOp\n2020-03-18 06:58:35.039689: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostRecv\" device_type: \"GPU\" host_memory_arg: \"tensor\"') for unknown op: _HostRecv\n2020-03-18 06:58:35.039886: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Send\" device_type: \"CPU\"') for unknown op: _Send\n2020-03-18 06:58:35.040043: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostRecv\" device_type: \"CPU\"') for unknown op: _HostRecv\n2020-03-18 06:58:35.040211: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Send\" device_type: \"GPU\"') for unknown op: _Send\n2020-03-18 06:58:35.040368: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Recv\" device_type: \"CPU\"') for unknown op: _Recv\n2020-03-18 06:58:35.040537: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostSend\" device_type: \"GPU\" host_memory_arg: \"tensor\"') for unknown op: _HostSend\n2020-03-18 06:58:35.040730: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Recv\" device_type: \"GPU\"') for unknown op: _Recv\n2020-03-18 06:58:35.040888: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostSend\" device_type: \"CPU\"') for unknown op: _HostSend\n2020-03-18 06:58:35.041056: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n2020-03-18 06:58:35.041244: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n2020-03-18 06:58:35.041602: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n2020-03-18 06:58:35.041827: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n2020-03-18 06:58:35.042222: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042364: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.042502: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042649: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.042783: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042920: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.043055: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.043281: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.043459: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.043636: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.043779: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.043927: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.044069: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.044214: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044348: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.044574: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044715: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.044853: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044987: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045127: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045262: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045403: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045620: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045760: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045892: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.046033: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.046181: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.046343: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.046564: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.046717: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\n2020-03-18 06:58:35.046855: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: LoopCond\n2020-03-18 06:58:35.047013: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.047146: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.047285: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.047500: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.047674: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.047827: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.047980: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.048129: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.048280: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.048458: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.048644: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.048795: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.048967: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.049118: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.049272: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.049473: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.049667: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.049861: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.051766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.051922: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052071: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052216: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052364: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052568: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052715: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052859: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053008: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053152: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053300: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053445: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053593: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053737: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053885: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054029: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054177: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054320: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054483: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054633: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054782: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.054917: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.055196: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055335: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.055524: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.055680: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.055816: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055954: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.056105: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.056257: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.056393: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.056532: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.056683: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.056839: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.056973: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057247: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057437: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057584: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057807: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057989: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058129: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058303: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058508: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058643: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058785: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058921: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059062: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059199: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059339: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059528: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059681: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059816: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059952: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060084: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.060223: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060358: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.060515: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.060675: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.060832: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060972: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061115: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061255: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061415: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061617: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061801: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061938: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.062079: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\n2020-03-18 06:58:35.062220: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: LoopCond\n2020-03-18 06:58:35.062387: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.062524: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.062662: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.062795: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.062935: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.063068: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.063266: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.063535: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.064249: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.064441: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.064649: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.064814: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.064981: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.065145: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.065312: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.065520: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.065682: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.065842: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066004: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066166: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066327: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066491: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066653: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066812: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066991: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.067156: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.067412: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.067593: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.067757: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.067925: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068092: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068251: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068450: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068656: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068818: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068987: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.069144: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.069293: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.069594: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\n2020-03-18 06:58:35.069779: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: NonMaxSuppressionV3\n2020-03-18 06:58:35.070031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\n2020-03-18 06:58:35.070195: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Size\n2020-03-18 06:58:35.070531: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\n2020-03-18 06:58:35.070743: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Size\n2020-03-18 06:58:35.070976: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.071142: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.071547: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.071782: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.071983: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072180: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.072367: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072562: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.072740: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072904: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.109919: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1041 operators, 1878 arrays (0 quantized)\n2020-03-18 06:58:35.197814: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 990 operators, 1776 arrays (0 quantized)\n2020-03-18 06:58:35.296904: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 990 operators, 1776 arrays (0 quantized)\n2020-03-18 06:58:35.376694: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.406643: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.430799: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.458977: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1080640 bytes, theoretical optimal value: 1080640 bytes.\n2020-03-18 06:58:35.463608: F tensorflow/lite/toco/tooling_util.cc:2258] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\nFatal Python error: Aborted\n\nCurrent thread 0x0000442c (most recent call first):\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33 in execute\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\absl\\app.py\", line 299 in run\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40 in run\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59 in main\n  File \"C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7 in <module>\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\runpy.py\", line 85 in _run_code\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\runpy.py\", line 193 in _run_module_as_main\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fbb49b792453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#converter = TFLiteConverter.from_saved_model(FINETUNED_MODEL_DIR + '/saved_model')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFLITE_MODEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m           **converter_kwargs)\n\u001b[0m\u001b[0;32m    899\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m       result = _toco_convert_graph_def(\n",
      "\u001b[1;32mc:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[0;32m    403\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                              input_data.SerializeToString())\n\u001b[0m\u001b[0;32m    405\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[0;32m    170\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m       raise ConverterError(\n\u001b[1;32m--> 172\u001b[1;33m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[0;32m    173\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: TOCO failed. See console for info.\n2020-03-18 06:58:35.038994: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.039329: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp\n2020-03-18 06:58:35.039530: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"NoOp\" device_type: \"GPU\"') for unknown op: NoOp\n2020-03-18 06:58:35.039689: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostRecv\" device_type: \"GPU\" host_memory_arg: \"tensor\"') for unknown op: _HostRecv\n2020-03-18 06:58:35.039886: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Send\" device_type: \"CPU\"') for unknown op: _Send\n2020-03-18 06:58:35.040043: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostRecv\" device_type: \"CPU\"') for unknown op: _HostRecv\n2020-03-18 06:58:35.040211: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Send\" device_type: \"GPU\"') for unknown op: _Send\n2020-03-18 06:58:35.040368: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Recv\" device_type: \"CPU\"') for unknown op: _Recv\n2020-03-18 06:58:35.040537: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostSend\" device_type: \"GPU\" host_memory_arg: \"tensor\"') for unknown op: _HostSend\n2020-03-18 06:58:35.040730: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_Recv\" device_type: \"GPU\"') for unknown op: _Recv\n2020-03-18 06:58:35.040888: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"_HostSend\" device_type: \"CPU\"') for unknown op: _HostSend\n2020-03-18 06:58:35.041056: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n2020-03-18 06:58:35.041244: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n2020-03-18 06:58:35.041602: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n2020-03-18 06:58:35.041827: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n2020-03-18 06:58:35.042222: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042364: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.042502: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042649: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.042783: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.042920: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.043055: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.043281: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.043459: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.043636: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.043779: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.043927: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.044069: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.044214: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044348: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.044574: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044715: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.044853: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.044987: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045127: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045262: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045403: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045620: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.045760: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.045892: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.046033: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.046181: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.046343: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.046564: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.046717: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\n2020-03-18 06:58:35.046855: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: LoopCond\n2020-03-18 06:58:35.047013: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.047146: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.047285: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.047500: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.047674: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.047827: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.047980: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.048129: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.048280: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.048458: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.048644: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.048795: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.048967: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.049118: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.049272: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.049473: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.049667: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.049861: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.051766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.051922: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052071: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052216: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052364: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052568: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.052715: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.052859: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053008: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053152: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053300: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053445: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053593: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.053737: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.053885: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054029: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054177: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054320: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054483: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\n2020-03-18 06:58:35.054633: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayV3\n2020-03-18 06:58:35.054782: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.054917: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.055196: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055335: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.055524: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.055680: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.055816: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.055954: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.056105: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.056257: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.056393: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.056532: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.056683: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.056839: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.056973: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057247: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057437: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057584: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.057807: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.057989: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058129: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058303: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058508: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058643: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.058785: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.058921: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059062: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059199: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059339: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059528: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059681: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.059816: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.059952: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060084: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.060223: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060358: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.060515: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.060675: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.060832: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.060972: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061115: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061255: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061415: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061617: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.061801: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.061938: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.062079: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\n2020-03-18 06:58:35.062220: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: LoopCond\n2020-03-18 06:58:35.062387: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.062524: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.062662: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.062795: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.062935: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.063068: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.063266: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\n2020-03-18 06:58:35.063535: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Exit\n2020-03-18 06:58:35.064249: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.064441: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.064649: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.064814: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.064981: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.065145: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.065312: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.065520: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.065682: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.065842: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066004: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066166: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066327: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066491: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066653: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\n2020-03-18 06:58:35.066812: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArraySizeV3\n2020-03-18 06:58:35.066991: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\n2020-03-18 06:58:35.067156: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayScatterV3\n2020-03-18 06:58:35.067412: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\n2020-03-18 06:58:35.067593: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Enter\n2020-03-18 06:58:35.067757: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.067925: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068092: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068251: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068450: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068656: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.068818: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\n2020-03-18 06:58:35.068987: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayGatherV3\n2020-03-18 06:58:35.069144: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\n2020-03-18 06:58:35.069293: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayReadV3\n2020-03-18 06:58:35.069594: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\n2020-03-18 06:58:35.069779: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: NonMaxSuppressionV3\n2020-03-18 06:58:35.070031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\n2020-03-18 06:58:35.070195: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Size\n2020-03-18 06:58:35.070531: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\n2020-03-18 06:58:35.070743: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: Size\n2020-03-18 06:58:35.070976: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.071142: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.071547: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.071782: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.071983: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072180: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.072367: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072562: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.072740: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\n2020-03-18 06:58:35.072904: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TensorArrayWriteV3\n2020-03-18 06:58:35.109919: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1041 operators, 1878 arrays (0 quantized)\n2020-03-18 06:58:35.197814: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 990 operators, 1776 arrays (0 quantized)\n2020-03-18 06:58:35.296904: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 990 operators, 1776 arrays (0 quantized)\n2020-03-18 06:58:35.376694: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.406643: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.430799: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 488 operators, 990 arrays (0 quantized)\n2020-03-18 06:58:35.458977: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1080640 bytes, theoretical optimal value: 1080640 bytes.\n2020-03-18 06:58:35.463608: F tensorflow/lite/toco/tooling_util.cc:2258] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\nFatal Python error: Aborted\n\nCurrent thread 0x0000442c (most recent call first):\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33 in execute\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\absl\\app.py\", line 299 in run\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40 in run\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59 in main\n  File \"C:\\Users\\Andreas\\Anaconda3\\envs\\tf1.14\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7 in <module>\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\runpy.py\", line 85 in _run_code\n  File \"c:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\runpy.py\", line 193 in _run_module_as_main\n\n\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.lite import TFLiteConverter, Optimize\n",
    "\n",
    "input_arrays=[\"image_tensor\"]\n",
    "output_arrays=[\"detection_boxes\",\"detection_scores\",\"num_detections\",\"detection_classes\"]\n",
    "input_tensor={\"image_tensor\":[1,300,300,3]}\n",
    "\n",
    "converter = TFLiteConverter.from_frozen_graph(PATH_TO_FROZEN_GRAPH, input_arrays, output_arrays, input_tensor)\n",
    "#converter = TFLiteConverter.from_saved_model(FINETUNED_MODEL_DIR + '/saved_model')\n",
    "converter.optimizations=[Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(TFLITE_MODEL_PATH, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provided has model identifier 'imag', should be 'TFL3'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-52b4add94701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load TFLite model and allocate tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPATH_TO_FROZEN_GRAPH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get input and output tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andreas\\anaconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content)\u001b[0m\n\u001b[0;32m     75\u001b[0m       self._interpreter = (\n\u001b[0;32m     76\u001b[0m           _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\n\u001b[1;32m---> 77\u001b[1;33m               model_path))\n\u001b[0m\u001b[0;32m     78\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to open {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Model provided has model identifier 'imag', should be 'TFL3'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.lite import Interpreter\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = Interpreter(model_path=PATH_TO_FROZEN_GRAPH)\n",
    "interpreter.allocate_tensors()\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "# Test model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "print(\"Input Shape:  {}\".format(input_shape))\n",
    "print(\"Input Details: {}\".format(input_details))\n",
    "print(\"Output Details: {}\".format(output_details))\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Output: {}\".format(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
